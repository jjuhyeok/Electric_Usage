{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------- Python & library version --------------------------\n",
      "Python version: 3.8.16 | packaged by conda-forge | (default, Feb  1 2023, 15:53:35) [MSC v.1929 64 bit (AMD64)]\n",
      "pandas version: 2.0.3\n",
      "numpy version: 1.24.3\n",
      "matplotlib version: 3.7.1\n",
      "tqdm version: 4.65.0\n",
      "sktime version: 0.20.1\n",
      "xgboost version: 1.7.6\n",
      "seaborn version: 0.12.2\n",
      "scikit-learn version: 1.2.2\n",
      "------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import sktime\n",
    "import tqdm as tq\n",
    "import xgboost as xgb\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import sklearn as skl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "from sktime.utils.plotting import plot_series\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "print(\"-------------------------- Python & library version --------------------------\")\n",
    "print(\"Python version: {}\".format(sys.version))\n",
    "print(\"pandas version: {}\".format(pd.__version__))\n",
    "print(\"numpy version: {}\".format(np.__version__))\n",
    "print(\"matplotlib version: {}\".format(matplotlib.__version__))\n",
    "print(\"tqdm version: {}\".format(tq.__version__))\n",
    "print(\"sktime version: {}\".format(sktime.__version__))\n",
    "print(\"xgboost version: {}\".format(xgb.__version__))\n",
    "print(\"seaborn version: {}\".format(sns.__version__))\n",
    "print(\"scikit-learn version: {}\".format(skl.__version__))\n",
    "print(\"------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = os.getcwd()\n",
    "parent_path = os.path.abspath(os.path.join(current_path, '..', '..','..'))\n",
    "sys.path.append(parent_path)\n",
    "pd.set_option('display.max_columns', 30)\n",
    "train = pd.read_csv('../../../../train.csv')\n",
    "train.drop(['num_date_time'],axis=1,inplace=True)\n",
    "test = pd.read_csv('../../../../test.csv')\n",
    "test.drop(['num_date_time'],axis=1,inplace=True)\n",
    "building = pd.read_csv('../../../../building_info.csv')\n",
    "test = pd.read_csv('../../../../merge_test_encoding.csv', encoding = \"CP949\")\n",
    "train_loc = pd.read_csv('../../../../train_location.csv')\n",
    "train = pd.concat([train,train_loc['location']],axis=1)\n",
    "def SMAPE(true, pred):\n",
    "    v = 2 * abs(pred - true) / (abs(pred) + abs(true))\n",
    "    output = np.mean(v) * 100\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import fillnan\n",
    "from preprocessing import preprocessing_all\n",
    "\n",
    "train, test = fillnan(train, test)\n",
    "train, test = preprocessing_all(train, test, building)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>date_time</th>\n",
       "      <th>temp</th>\n",
       "      <th>rainy</th>\n",
       "      <th>wind</th>\n",
       "      <th>hum</th>\n",
       "      <th>power</th>\n",
       "      <th>location</th>\n",
       "      <th>연면적</th>\n",
       "      <th>냉방면적</th>\n",
       "      <th>태양광용량</th>\n",
       "      <th>ESS저장용량</th>\n",
       "      <th>PCS용량</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>...</th>\n",
       "      <th>아파트</th>\n",
       "      <th>연구소</th>\n",
       "      <th>지식산업센터</th>\n",
       "      <th>할인마트</th>\n",
       "      <th>호텔및리조트</th>\n",
       "      <th>tem_x_hum</th>\n",
       "      <th>commute_period</th>\n",
       "      <th>body_temp</th>\n",
       "      <th>low_power_day</th>\n",
       "      <th>power_diff_ratio</th>\n",
       "      <th>power_increase_summer</th>\n",
       "      <th>증가_day_hour_sum</th>\n",
       "      <th>감소_day_hour_sum</th>\n",
       "      <th>increase_all</th>\n",
       "      <th>decrease_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20220601 00</td>\n",
       "      <td>18.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1085.28</td>\n",
       "      <td>11</td>\n",
       "      <td>110634.00</td>\n",
       "      <td>39570.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>781.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20220608 00</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1124.16</td>\n",
       "      <td>11</td>\n",
       "      <td>110634.00</td>\n",
       "      <td>39570.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1159.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>20220615 00</td>\n",
       "      <td>17.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1182.24</td>\n",
       "      <td>11</td>\n",
       "      <td>110634.00</td>\n",
       "      <td>39570.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1274.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>20220622 00</td>\n",
       "      <td>24.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1257.60</td>\n",
       "      <td>11</td>\n",
       "      <td>110634.00</td>\n",
       "      <td>39570.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1928.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20220629 00</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3.5</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1224.00</td>\n",
       "      <td>11</td>\n",
       "      <td>110634.00</td>\n",
       "      <td>39570.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2287.3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203995</th>\n",
       "      <td>100</td>\n",
       "      <td>20220726 23</td>\n",
       "      <td>25.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>90.0</td>\n",
       "      <td>610.32</td>\n",
       "      <td>9</td>\n",
       "      <td>57497.84</td>\n",
       "      <td>40035.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2331.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203996</th>\n",
       "      <td>100</td>\n",
       "      <td>20220802 23</td>\n",
       "      <td>26.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>655.68</td>\n",
       "      <td>9</td>\n",
       "      <td>57497.84</td>\n",
       "      <td>40035.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2421.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203997</th>\n",
       "      <td>100</td>\n",
       "      <td>20220809 23</td>\n",
       "      <td>27.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>82.0</td>\n",
       "      <td>650.40</td>\n",
       "      <td>9</td>\n",
       "      <td>57497.84</td>\n",
       "      <td>40035.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2279.6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203998</th>\n",
       "      <td>100</td>\n",
       "      <td>20220816 23</td>\n",
       "      <td>24.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>98.0</td>\n",
       "      <td>669.12</td>\n",
       "      <td>9</td>\n",
       "      <td>57497.84</td>\n",
       "      <td>40035.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203999</th>\n",
       "      <td>100</td>\n",
       "      <td>20220823 23</td>\n",
       "      <td>22.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>93.0</td>\n",
       "      <td>610.32</td>\n",
       "      <td>9</td>\n",
       "      <td>57497.84</td>\n",
       "      <td>40035.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2055.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204000 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        num    date_time  temp  rainy  wind   hum    power  location  \\\n",
       "0         1  20220601 00  18.6    0.0   0.9  42.0  1085.28        11   \n",
       "1         1  20220608 00  19.0    0.0   3.2  61.0  1124.16        11   \n",
       "2         1  20220615 00  17.7    0.0   3.3  72.0  1182.24        11   \n",
       "3         1  20220622 00  24.1    0.0   2.5  80.0  1257.60        11   \n",
       "4         1  20220629 00  25.7    0.8   3.5  89.0  1224.00        11   \n",
       "...     ...          ...   ...    ...   ...   ...      ...       ...   \n",
       "203995  100  20220726 23  25.9    0.0   0.1  90.0   610.32         9   \n",
       "203996  100  20220802 23  26.9    0.0   1.0  90.0   655.68         9   \n",
       "203997  100  20220809 23  27.8    0.0   2.2  82.0   650.40         9   \n",
       "203998  100  20220816 23  24.5    0.0   0.1  98.0   669.12         9   \n",
       "203999  100  20220823 23  22.1    0.0   0.7  93.0   610.32         9   \n",
       "\n",
       "              연면적      냉방면적  태양광용량  ESS저장용량  PCS용량  hour  day  ...  아파트  연구소  \\\n",
       "0       110634.00  39570.00    0.0      0.0    0.0     0    2  ...    0    0   \n",
       "1       110634.00  39570.00    0.0      0.0    0.0     0    2  ...    0    0   \n",
       "2       110634.00  39570.00    0.0      0.0    0.0     0    2  ...    0    0   \n",
       "3       110634.00  39570.00    0.0      0.0    0.0     0    2  ...    0    0   \n",
       "4       110634.00  39570.00    0.0      0.0    0.0     0    2  ...    0    0   \n",
       "...           ...       ...    ...      ...    ...   ...  ...  ...  ...  ...   \n",
       "203995   57497.84  40035.23    0.0      0.0    0.0    23    1  ...    0    0   \n",
       "203996   57497.84  40035.23    0.0      0.0    0.0    23    1  ...    0    0   \n",
       "203997   57497.84  40035.23    0.0      0.0    0.0    23    1  ...    0    0   \n",
       "203998   57497.84  40035.23    0.0      0.0    0.0    23    1  ...    0    0   \n",
       "203999   57497.84  40035.23    0.0      0.0    0.0    23    1  ...    0    0   \n",
       "\n",
       "        지식산업센터  할인마트  호텔및리조트  tem_x_hum  commute_period  body_temp  \\\n",
       "0            0     0       0      781.2               0          0   \n",
       "1            0     0       0     1159.0               0          0   \n",
       "2            0     0       0     1274.4               0          0   \n",
       "3            0     0       0     1928.0               0          1   \n",
       "4            0     0       0     2287.3               0          2   \n",
       "...        ...   ...     ...        ...             ...        ...   \n",
       "203995       0     0       1     2331.0               0          2   \n",
       "203996       0     0       1     2421.0               0          2   \n",
       "203997       0     0       1     2279.6               0          2   \n",
       "203998       0     0       1     2401.0               0          1   \n",
       "203999       0     0       1     2055.3               0          1   \n",
       "\n",
       "        low_power_day  power_diff_ratio  power_increase_summer  \\\n",
       "0                 0.0               0.0                      0   \n",
       "1                 0.0               0.0                      0   \n",
       "2                 0.0               0.0                      0   \n",
       "3                 0.0               0.0                      0   \n",
       "4                 0.0               0.0                      0   \n",
       "...               ...               ...                    ...   \n",
       "203995            0.0               0.0                      0   \n",
       "203996            0.0               0.0                      0   \n",
       "203997            0.0               0.0                      0   \n",
       "203998            0.0               0.0                      0   \n",
       "203999            0.0               0.0                      0   \n",
       "\n",
       "        증가_day_hour_sum  감소_day_hour_sum  increase_all  decrease_all  \n",
       "0                     0               12             0             1  \n",
       "1                     0               12             0             1  \n",
       "2                     0               12             0             1  \n",
       "3                     0               12             0             1  \n",
       "4                     0               12             0             1  \n",
       "...                 ...              ...           ...           ...  \n",
       "203995                0               12             0             1  \n",
       "203996                0               12             0             1  \n",
       "203997                0               12             0             1  \n",
       "203998                0               12             0             1  \n",
       "203999                0               12             0             1  \n",
       "\n",
       "[204000 rows x 49 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from preprocessing import preprocessing_all\n",
    "from fe import new_fe\n",
    "train, test = new_fe(train, test)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['연면_냉방면적'] = train['연면적'] / (train['냉방면적'])\n",
    "test['연면_냉방면적'] = test['연면적'] / (test['냉방면적'])\n",
    "train['태양광효율'] = train['연면적'] / (train['태양광용량'] + 1)\n",
    "test['태양광효율'] = test['연면적'] / (test['태양광용량'] + 1)\n",
    "train['태양광효율'] = train['연면적'] / (train['태양광용량'] + 1)\n",
    "test['태양광효율'] = test['연면적'] / (test['태양광용량'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_rainy_category(group):\n",
    "    rainy_count = (group['rainy'] > 0).sum()\n",
    "    if rainy_count == 0:\n",
    "        return 0\n",
    "    elif rainy_count > 0 and rainy_count <= 3:\n",
    "        return 1\n",
    "    elif rainy_count > 3 and rainy_count <= 9:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "rainy_categories = train.groupby(['num', 'week', 'day']).apply(assign_rainy_category).reset_index(name='rainy_category')\n",
    "train = pd.merge(train, rainy_categories, on=['num', 'week', 'day'], how='left')\n",
    "\n",
    "rainy_categories_test = test.groupby(['num', 'week', 'day']).apply(assign_rainy_category).reset_index(name='rainy_category')\n",
    "test = pd.merge(test, rainy_categories_test, on=['num', 'week', 'day'], how='left')\n",
    "train = train.sort_values(['num','date_time'])\n",
    "test = test.sort_values(['num','date_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 폭염 경보, 폭염 주의보, 열대야 피처를 초기화합니다.\n",
    "train['heatwave_alert'] = 0\n",
    "train['heatwave_caution'] = 0\n",
    "train['tropical_night'] = 0\n",
    "\n",
    "# 빌딩 ID별로 루프를 돕니다.\n",
    "for building_id in train['num'].unique():\n",
    "    # 해당 빌딩의 데이터만 선택\n",
    "    building_data = train[train['num'] == building_id]\n",
    "\n",
    "    # 년월일별로 루프를 돕니다.\n",
    "    for date in building_data['date_time'].apply(lambda x: x.split(' ')[0]).unique():\n",
    "        # 해당 빌딩, 날짜의 데이터만 선택\n",
    "        daily_data = building_data[building_data['date_time'].str.startswith(date)]\n",
    "\n",
    "        # 최대 온도 계산\n",
    "        max_temp = daily_data['temp'].max()\n",
    "\n",
    "        # 35도 이상이면 폭염 경보 1\n",
    "        if max_temp >= 35:\n",
    "            train.loc[(train['num'] == building_id) & (train['date_time'].str.startswith(date)), 'heatwave_alert'] = 1\n",
    "\n",
    "        # 33도 이상이면 폭염 주의보 1\n",
    "        if max_temp >= 33:\n",
    "            train.loc[(train['num'] == building_id) & (train['date_time'].str.startswith(date)), 'heatwave_caution'] = 1\n",
    "\n",
    "        # 모든 시간대의 온도가 25도 이상이면 열대야 1\n",
    "        if daily_data['temp'].min() >= 25:\n",
    "            train.loc[(train['num'] == building_id) & (train['date_time'].str.startswith(date)), 'tropical_night'] = 1\n",
    "\n",
    "\n",
    "test['heatwave_alert'] = 0\n",
    "test['heatwave_caution'] = 0\n",
    "test['tropical_night'] = 0\n",
    "\n",
    "# 빌딩 ID별로 루프를 돕니다.\n",
    "for building_id in test['num'].unique():\n",
    "    # 해당 빌딩의 데이터만 선택\n",
    "    building_data = test[test['num'] == building_id]\n",
    "\n",
    "    # 년월일별로 루프를 돕니다.\n",
    "    for date in building_data['date_time'].apply(lambda x: x.split(' ')[0]).unique():\n",
    "        # 해당 빌딩, 날짜의 데이터만 선택\n",
    "        daily_data = building_data[building_data['date_time'].str.startswith(date)]\n",
    "\n",
    "        # 최대 온도 계산\n",
    "        max_temp = daily_data['temp'].max()\n",
    "\n",
    "        # 35도 이상이면 폭염 경보 1\n",
    "        if max_temp >= 35:\n",
    "            test.loc[(test['num'] == building_id) & (test['date_time'].str.startswith(date)), 'heatwave_alert'] = 1\n",
    "\n",
    "        # 33도 이상이면 폭염 주의보 1\n",
    "        if max_temp >= 33:\n",
    "            test.loc[(test['num'] == building_id) & (test['date_time'].str.startswith(date)), 'heatwave_caution'] = 1\n",
    "\n",
    "        # 모든 시간대의 온도가 25도 이상이면 열대야 1\n",
    "        if daily_data['temp'].min() >= 25:\n",
    "            test.loc[(test['num'] == building_id) & (test['date_time'].str.startswith(date)), 'tropical_night'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['temp_wind'] = train['temp'] / (train['wind']+1)\n",
    "test['temp_wind'] = test['temp'] / (test['wind']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 원-핫 인코딩된 피처들\n",
    "onehot_features = ['건물기타', '공공', '대학교', '데이터센터', '백화점및아울렛', '병원', '상용', '아파트', '연구소',\n",
    "       '지식산업센터', '할인마트', '호텔및리조트']\n",
    "\n",
    "# 원-핫 인코딩된 피처들에 대해 각 행에서 1의 값을 갖는 열의 이름을 얻음\n",
    "train['building_type'] = train[onehot_features].idxmax(axis=1)\n",
    "test['building_type'] = test[onehot_features].idxmax(axis=1)\n",
    "\n",
    "# 라벨 인코더 생성\n",
    "le = LabelEncoder()\n",
    "\n",
    "# 'building_type' 열에 라벨 인코딩 적용\n",
    "train['building_type'] = le.fit_transform(train['building_type'])\n",
    "test['building_type'] = le.transform(test['building_type'])\n",
    "\n",
    "# 원-핫 인코딩된 열 삭제\n",
    "train = train.drop(columns=onehot_features)\n",
    "test = test.drop(columns=onehot_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['building_type'],axis=1,inplace=True)\n",
    "test.drop(['building_type'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>date_time</th>\n",
       "      <th>temp</th>\n",
       "      <th>rainy</th>\n",
       "      <th>wind</th>\n",
       "      <th>hum</th>\n",
       "      <th>power</th>\n",
       "      <th>location</th>\n",
       "      <th>연면적</th>\n",
       "      <th>냉방면적</th>\n",
       "      <th>태양광용량</th>\n",
       "      <th>ESS저장용량</th>\n",
       "      <th>PCS용량</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>...</th>\n",
       "      <th>power_diff_ratio</th>\n",
       "      <th>power_increase_summer</th>\n",
       "      <th>증가_day_hour_sum</th>\n",
       "      <th>감소_day_hour_sum</th>\n",
       "      <th>increase_all</th>\n",
       "      <th>decrease_all</th>\n",
       "      <th>연면_냉방면적</th>\n",
       "      <th>태양광효율</th>\n",
       "      <th>rainy_category</th>\n",
       "      <th>heatwave_alert</th>\n",
       "      <th>heatwave_caution</th>\n",
       "      <th>tropical_night</th>\n",
       "      <th>temp_wind</th>\n",
       "      <th>temp_diff</th>\n",
       "      <th>tem_x_hum_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20220601 00</td>\n",
       "      <td>18.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1085.28</td>\n",
       "      <td>11</td>\n",
       "      <td>110634.00</td>\n",
       "      <td>39570.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.795906</td>\n",
       "      <td>110634.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.789474</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20220601 01</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1047.36</td>\n",
       "      <td>11</td>\n",
       "      <td>110634.00</td>\n",
       "      <td>39570.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.795906</td>\n",
       "      <td>110634.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.571429</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>20220601 02</td>\n",
       "      <td>17.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>45.0</td>\n",
       "      <td>974.88</td>\n",
       "      <td>11</td>\n",
       "      <td>110634.00</td>\n",
       "      <td>39570.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.795906</td>\n",
       "      <td>110634.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.080000</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>20220601 03</td>\n",
       "      <td>16.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>48.0</td>\n",
       "      <td>953.76</td>\n",
       "      <td>11</td>\n",
       "      <td>110634.00</td>\n",
       "      <td>39570.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.795906</td>\n",
       "      <td>110634.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.958333</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20220601 04</td>\n",
       "      <td>18.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>43.0</td>\n",
       "      <td>986.40</td>\n",
       "      <td>11</td>\n",
       "      <td>110634.00</td>\n",
       "      <td>39570.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.795906</td>\n",
       "      <td>110634.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.842105</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203995</th>\n",
       "      <td>100</td>\n",
       "      <td>20220824 19</td>\n",
       "      <td>23.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>86.0</td>\n",
       "      <td>881.04</td>\n",
       "      <td>9</td>\n",
       "      <td>57497.84</td>\n",
       "      <td>40035.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.436181</td>\n",
       "      <td>57497.84</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.157895</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203996</th>\n",
       "      <td>100</td>\n",
       "      <td>20220824 20</td>\n",
       "      <td>22.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>86.0</td>\n",
       "      <td>798.96</td>\n",
       "      <td>9</td>\n",
       "      <td>57497.84</td>\n",
       "      <td>40035.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.436181</td>\n",
       "      <td>57497.84</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.739130</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203997</th>\n",
       "      <td>100</td>\n",
       "      <td>20220824 21</td>\n",
       "      <td>21.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>825.12</td>\n",
       "      <td>9</td>\n",
       "      <td>57497.84</td>\n",
       "      <td>40035.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.436181</td>\n",
       "      <td>57497.84</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.650000</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203998</th>\n",
       "      <td>100</td>\n",
       "      <td>20220824 22</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>94.0</td>\n",
       "      <td>640.08</td>\n",
       "      <td>9</td>\n",
       "      <td>57497.84</td>\n",
       "      <td>40035.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.436181</td>\n",
       "      <td>57497.84</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16.153846</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203999</th>\n",
       "      <td>100</td>\n",
       "      <td>20220824 23</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>95.0</td>\n",
       "      <td>540.24</td>\n",
       "      <td>9</td>\n",
       "      <td>57497.84</td>\n",
       "      <td>40035.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.436181</td>\n",
       "      <td>57497.84</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.818182</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204000 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        num    date_time  temp  rainy  wind   hum    power  location  \\\n",
       "0         1  20220601 00  18.6    0.0   0.9  42.0  1085.28        11   \n",
       "1         1  20220601 01  18.0    0.0   1.1  45.0  1047.36        11   \n",
       "2         1  20220601 02  17.7    0.0   1.5  45.0   974.88        11   \n",
       "3         1  20220601 03  16.7    0.0   1.4  48.0   953.76        11   \n",
       "4         1  20220601 04  18.4    0.0   2.8  43.0   986.40        11   \n",
       "...     ...          ...   ...    ...   ...   ...      ...       ...   \n",
       "203995  100  20220824 19  23.1    0.0   0.9  86.0   881.04         9   \n",
       "203996  100  20220824 20  22.4    0.0   1.3  86.0   798.96         9   \n",
       "203997  100  20220824 21  21.3    0.0   1.0  92.0   825.12         9   \n",
       "203998  100  20220824 22  21.0    0.0   0.3  94.0   640.08         9   \n",
       "203999  100  20220824 23  20.7    0.0   0.1  95.0   540.24         9   \n",
       "\n",
       "              연면적      냉방면적  태양광용량  ESS저장용량  PCS용량  hour  day  ...  \\\n",
       "0       110634.00  39570.00    0.0      0.0    0.0     0    2  ...   \n",
       "1       110634.00  39570.00    0.0      0.0    0.0     1    2  ...   \n",
       "2       110634.00  39570.00    0.0      0.0    0.0     2    2  ...   \n",
       "3       110634.00  39570.00    0.0      0.0    0.0     3    2  ...   \n",
       "4       110634.00  39570.00    0.0      0.0    0.0     4    2  ...   \n",
       "...           ...       ...    ...      ...    ...   ...  ...  ...   \n",
       "203995   57497.84  40035.23    0.0      0.0    0.0    19    2  ...   \n",
       "203996   57497.84  40035.23    0.0      0.0    0.0    20    2  ...   \n",
       "203997   57497.84  40035.23    0.0      0.0    0.0    21    2  ...   \n",
       "203998   57497.84  40035.23    0.0      0.0    0.0    22    2  ...   \n",
       "203999   57497.84  40035.23    0.0      0.0    0.0    23    2  ...   \n",
       "\n",
       "        power_diff_ratio  power_increase_summer  증가_day_hour_sum  \\\n",
       "0                    0.0                      0                0   \n",
       "1                    0.0                      0                0   \n",
       "2                    0.0                      0                0   \n",
       "3                    0.0                      0                0   \n",
       "4                    0.0                      0                8   \n",
       "...                  ...                    ...              ...   \n",
       "203995               0.0                      0                0   \n",
       "203996               0.0                      0                0   \n",
       "203997               0.0                      0                1   \n",
       "203998               0.0                      0                0   \n",
       "203999               0.0                      0                0   \n",
       "\n",
       "        감소_day_hour_sum  increase_all  decrease_all   연면_냉방면적      태양광효율  \\\n",
       "0                    12             0             1  2.795906  110634.00   \n",
       "1                    13             0             1  2.795906  110634.00   \n",
       "2                    13             0             1  2.795906  110634.00   \n",
       "3                    13             0             1  2.795906  110634.00   \n",
       "4                     5             0             0  2.795906  110634.00   \n",
       "...                 ...           ...           ...       ...        ...   \n",
       "203995               13             0             1  1.436181   57497.84   \n",
       "203996               13             0             1  1.436181   57497.84   \n",
       "203997               12             0             0  1.436181   57497.84   \n",
       "203998               13             0             1  1.436181   57497.84   \n",
       "203999               13             0             1  1.436181   57497.84   \n",
       "\n",
       "        rainy_category  heatwave_alert  heatwave_caution  tropical_night  \\\n",
       "0                    0               0                 0               0   \n",
       "1                    0               0                 0               0   \n",
       "2                    0               0                 0               0   \n",
       "3                    0               0                 0               0   \n",
       "4                    0               0                 0               0   \n",
       "...                ...             ...               ...             ...   \n",
       "203995               1               0                 0               0   \n",
       "203996               1               0                 0               0   \n",
       "203997               1               0                 0               0   \n",
       "203998               1               0                 0               0   \n",
       "203999               1               0                 0               0   \n",
       "\n",
       "        temp_wind  temp_diff  tem_x_hum_diff  \n",
       "0        9.789474          0               0  \n",
       "1        8.571429         -1               1  \n",
       "2        7.080000         -1              -1  \n",
       "3        6.958333         -1               1  \n",
       "4        4.842105          1              -1  \n",
       "...           ...        ...             ...  \n",
       "203995  12.157895         -1               1  \n",
       "203996   9.739130         -1              -1  \n",
       "203997  10.650000         -1               1  \n",
       "203998  16.153846         -1               1  \n",
       "203999  18.818182         -1              -1  \n",
       "\n",
       "[204000 rows x 46 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train과 test에 각각 'is_train' 열 추가\n",
    "train['is_train'] = True\n",
    "test['is_train'] = False\n",
    "\n",
    "# train과 test 데이터프레임을 병합\n",
    "combined = pd.concat([train, test], ignore_index=True)\n",
    "\n",
    "# 'num'과 'date_time'을 기준으로 정렬\n",
    "combined = combined.sort_values(['num', 'date_time'])\n",
    "\n",
    "# 온도 차이 계산 함수\n",
    "def calculate_temp_diff(group):\n",
    "    group['temp_diff'] = group['temp'].diff().fillna(0)\n",
    "    group['tem_x_hum_diff'] = group['tem_x_hum'].diff().fillna(0)\n",
    "\n",
    "    return group\n",
    "\n",
    "# 'num' 열을 기준으로 그룹화하고 calculate_temp_diff 함수 적용\n",
    "combined = combined.groupby('num').apply(calculate_temp_diff)\n",
    "\n",
    "# 'is_train' 열을 기준으로 train과 test 데이터를 다시 나눔\n",
    "train = combined[combined['is_train'] == True].drop(columns=['is_train'])\n",
    "test = combined[combined['is_train'] == False].drop(columns=['is_train'])\n",
    "# temp_diff 피처의 값이 양수면 1, 음수면 -1로 변경\n",
    "train['temp_diff'] = train['temp_diff'].apply(lambda x: 1 if x > 0 else (-1 if x < 0 else 0))\n",
    "test['temp_diff'] = test['temp_diff'].apply(lambda x: 1 if x > 0 else (-1 if x < 0 else 0))\n",
    "\n",
    "# tem_x_hum_diff 피처의 값이 양수면 1, 음수면 -1로 변경\n",
    "train['tem_x_hum_diff'] = train['tem_x_hum_diff'].apply(lambda x: 1 if x > 0 else (-1 if x < 0 else 0))\n",
    "test['tem_x_hum_diff'] = test['tem_x_hum_diff'].apply(lambda x: 1 if x > 0 else (-1 if x < 0 else 0))\n",
    "\n",
    "\n",
    "# 필요한 경우 인덱스 재설정\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_mse(alpha = 1):\n",
    "    def weighted_mse_fixed(label, pred):\n",
    "        residual = (label - pred).astype(\"float\")\n",
    "        grad = np.where(residual>0, -2*alpha*residual, -2*residual)\n",
    "        hess = np.where(residual>0, 2*alpha, 2.0)\n",
    "        return grad, hess\n",
    "    return weighted_mse_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna import Trial\n",
    "from optuna.samplers import TPESampler\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def objective_xgb(trial: Trial, X_train, y_train, X_val, y_val):\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int('n_estimators', 500, 5000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 8, 16),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n",
    "        'gamma': trial.suggest_int('gamma', 1, 3),\n",
    "        'learning_rate': trial.suggest_categorical('learning_rate', [0.008,0.01,0.012,0.014,0.016,0.018, 0.02]),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
    "        #'alpha': trial.suggest_loguniform('alpha', 1e-3, 100.0),\n",
    "        'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
    "        'subsample': trial.suggest_categorical('subsample', [0.6, 0.7, 0.8, 1.0]),\n",
    "        'random_state': 953\n",
    "    }\n",
    "\n",
    "    model = XGBRegressor(**params, tree_method='gpu_hist', gpu_id=0, seed=953)\n",
    "    alpha_value = model.get_params()['alpha']\n",
    "    model.set_params(**{'objective':weighted_mse(alpha_value)})\n",
    "    model.fit(X_train, y_train, verbose = False, eval_set=[(X_val, y_val)], early_stopping_rounds=50)\n",
    "    y_pred = model.predict(X_val)\n",
    "    score = SMAPE(y_val, y_pred)\n",
    "\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 34 / 5 따로 fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-03 22:23:56,491] A new study created in memory with name: no-name-99d8fe81-5131-4254-99fc-429d69abe192\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-03 22:30:11,309] Trial 0 finished with value: 3.5494515329654237 and parameters: {'n_estimators': 4022, 'max_depth': 11, 'min_child_weight': 96, 'gamma': 1, 'learning_rate': 0.016, 'colsample_bytree': 0.9566721290616316, 'lambda': 3.319824961497244, 'alpha': 4.401367547099768, 'subsample': 0.8}. Best is trial 0 with value: 3.5494515329654237.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-03 22:33:04,472] Trial 1 finished with value: 4.317498948439812 and parameters: {'n_estimators': 1398, 'max_depth': 13, 'min_child_weight': 53, 'gamma': 1, 'learning_rate': 0.02, 'colsample_bytree': 0.8843932241283159, 'lambda': 3.861483344688794, 'alpha': 18.632054214654307, 'subsample': 0.8}. Best is trial 0 with value: 3.5494515329654237.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-03 22:39:20,274] Trial 2 finished with value: 5.418946914502543 and parameters: {'n_estimators': 2793, 'max_depth': 14, 'min_child_weight': 135, 'gamma': 1, 'learning_rate': 0.014, 'colsample_bytree': 0.5997651738831762, 'lambda': 0.03289805047034936, 'alpha': 23.30835906623709, 'subsample': 1.0}. Best is trial 0 with value: 3.5494515329654237.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-03 22:43:21,079] Trial 3 finished with value: 3.9287747755265 and parameters: {'n_estimators': 2584, 'max_depth': 9, 'min_child_weight': 176, 'gamma': 1, 'learning_rate': 0.012, 'colsample_bytree': 0.8375831214255278, 'lambda': 0.0031603499707020142, 'alpha': 2.2003279726485077, 'subsample': 0.7}. Best is trial 0 with value: 3.5494515329654237.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-03 22:49:14,539] Trial 4 finished with value: 4.289011104245502 and parameters: {'n_estimators': 3666, 'max_depth': 11, 'min_child_weight': 210, 'gamma': 1, 'learning_rate': 0.01, 'colsample_bytree': 0.7025978763740028, 'lambda': 3.620185712344573, 'alpha': 4.300822849908272, 'subsample': 1.0}. Best is trial 0 with value: 3.5494515329654237.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-03 22:56:42,950] Trial 5 finished with value: 6.369789447620867 and parameters: {'n_estimators': 4573, 'max_depth': 10, 'min_child_weight': 280, 'gamma': 2, 'learning_rate': 0.012, 'colsample_bytree': 0.5240466353806617, 'lambda': 0.28030707193634324, 'alpha': 34.90569161106633, 'subsample': 0.8}. Best is trial 0 with value: 3.5494515329654237.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-03 22:57:24,117] Trial 6 finished with value: 4.310822731979718 and parameters: {'n_estimators': 951, 'max_depth': 13, 'min_child_weight': 207, 'gamma': 3, 'learning_rate': 0.02, 'colsample_bytree': 0.8967211286885655, 'lambda': 0.06911911133988757, 'alpha': 8.418968102778079, 'subsample': 1.0}. Best is trial 0 with value: 3.5494515329654237.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-03 22:57:45,758] Trial 7 finished with value: 16.10512619719242 and parameters: {'n_estimators': 2364, 'max_depth': 13, 'min_child_weight': 9, 'gamma': 3, 'learning_rate': 0.016, 'colsample_bytree': 0.5159303997960151, 'lambda': 8.702880595343625, 'alpha': 2.7596364415337336, 'subsample': 1.0}. Best is trial 0 with value: 3.5494515329654237.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-03 22:58:33,045] Trial 8 finished with value: 5.690023027118352 and parameters: {'n_estimators': 4344, 'max_depth': 8, 'min_child_weight': 9, 'gamma': 1, 'learning_rate': 0.01, 'colsample_bytree': 0.9116457331352061, 'lambda': 4.792704607792597, 'alpha': 15.383227864721064, 'subsample': 1.0}. Best is trial 0 with value: 3.5494515329654237.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-03 23:03:57,856] Trial 9 finished with value: 3.595008865896504 and parameters: {'n_estimators': 3518, 'max_depth': 9, 'min_child_weight': 168, 'gamma': 1, 'learning_rate': 0.016, 'colsample_bytree': 0.9571384470481978, 'lambda': 0.008096648140970913, 'alpha': 1.4409522388873794, 'subsample': 1.0}. Best is trial 0 with value: 3.5494515329654237.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-03 23:06:20,037] Trial 10 finished with value: 3.5496289700964425 and parameters: {'n_estimators': 4983, 'max_depth': 16, 'min_child_weight': 94, 'gamma': 2, 'learning_rate': 0.018, 'colsample_bytree': 0.9893449485919364, 'lambda': 0.6184073872237028, 'alpha': 77.10543544359842, 'subsample': 0.6}. Best is trial 0 with value: 3.5494515329654237.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-03 23:08:44,753] Trial 11 finished with value: 3.559626806581414 and parameters: {'n_estimators': 4549, 'max_depth': 16, 'min_child_weight': 103, 'gamma': 2, 'learning_rate': 0.018, 'colsample_bytree': 0.9849619267444301, 'lambda': 0.5582224275445506, 'alpha': 91.61826322904209, 'subsample': 0.6}. Best is trial 0 with value: 3.5494515329654237.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-03 23:11:33,670] Trial 12 finished with value: 3.53111767918068 and parameters: {'n_estimators': 3998, 'max_depth': 16, 'min_child_weight': 90, 'gamma': 2, 'learning_rate': 0.008, 'colsample_bytree': 0.9989184429623631, 'lambda': 0.8175626059983417, 'alpha': 7.302509009539207, 'subsample': 0.6}. Best is trial 12 with value: 3.53111767918068.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-03 23:12:46,272] Trial 13 finished with value: 4.589213800332116 and parameters: {'n_estimators': 3495, 'max_depth': 11, 'min_child_weight': 81, 'gamma': 2, 'learning_rate': 0.008, 'colsample_bytree': 0.8102037440097198, 'lambda': 1.2654202087946045, 'alpha': 6.260770290444927, 'subsample': 0.6}. Best is trial 12 with value: 3.53111767918068.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-03 23:21:39,498] Trial 14 finished with value: 3.1019215716403106 and parameters: {'n_estimators': 3939, 'max_depth': 15, 'min_child_weight': 49, 'gamma': 3, 'learning_rate': 0.008, 'colsample_bytree': 0.9956855147668304, 'lambda': 1.2388351204476948, 'alpha': 4.8127537702684045, 'subsample': 0.8}. Best is trial 14 with value: 3.1019215716403106.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-03 23:30:02,661] Trial 15 finished with value: 4.028402870625318 and parameters: {'n_estimators': 3068, 'max_depth': 15, 'min_child_weight': 48, 'gamma': 3, 'learning_rate': 0.008, 'colsample_bytree': 0.7784954816506259, 'lambda': 0.12587698914135975, 'alpha': 8.62254633401614, 'subsample': 0.7}. Best is trial 14 with value: 3.1019215716403106.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-03 23:33:29,771] Trial 16 finished with value: 3.3244228484157112 and parameters: {'n_estimators': 1965, 'max_depth': 15, 'min_child_weight': 48, 'gamma': 3, 'learning_rate': 0.008, 'colsample_bytree': 0.9941303103024979, 'lambda': 1.7417695642712276, 'alpha': 1.124289267841043, 'subsample': 0.6}. Best is trial 14 with value: 3.1019215716403106.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-03 23:37:00,925] Trial 17 finished with value: 3.5819263305171933 and parameters: {'n_estimators': 1967, 'max_depth': 14, 'min_child_weight': 41, 'gamma': 3, 'learning_rate': 0.008, 'colsample_bytree': 0.8645281025589201, 'lambda': 1.5894549127244766, 'alpha': 1.1034794449216527, 'subsample': 0.8}. Best is trial 14 with value: 3.1019215716403106.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-03 23:40:05,674] Trial 18 finished with value: 3.5887397149157017 and parameters: {'n_estimators': 1885, 'max_depth': 15, 'min_child_weight': 132, 'gamma': 3, 'learning_rate': 0.008, 'colsample_bytree': 0.9269999336401529, 'lambda': 0.25861773914768915, 'alpha': 1.0271485205525688, 'subsample': 0.6}. Best is trial 14 with value: 3.1019215716403106.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-03 23:41:28,426] Trial 19 finished with value: 4.040455517733981 and parameters: {'n_estimators': 508, 'max_depth': 15, 'min_child_weight': 31, 'gamma': 3, 'learning_rate': 0.014, 'colsample_bytree': 0.9321347626908443, 'lambda': 1.6714532811901737, 'alpha': 2.057835261976067, 'subsample': 0.8}. Best is trial 14 with value: 3.1019215716403106.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-03 23:44:38,529] Trial 20 finished with value: 3.95585604092306 and parameters: {'n_estimators': 1904, 'max_depth': 14, 'min_child_weight': 277, 'gamma': 3, 'learning_rate': 0.008, 'colsample_bytree': 0.8488374818424211, 'lambda': 0.34952221463780137, 'alpha': 3.100992542163455, 'subsample': 0.7}. Best is trial 14 with value: 3.1019215716403106.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-03 23:52:13,007] Trial 21 finished with value: 3.195210711658531 and parameters: {'n_estimators': 3127, 'max_depth': 16, 'min_child_weight': 64, 'gamma': 2, 'learning_rate': 0.008, 'colsample_bytree': 0.9940547138486324, 'lambda': 1.0291204606372433, 'alpha': 5.267815903697607, 'subsample': 0.6}. Best is trial 14 with value: 3.1019215716403106.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-03 23:58:30,152] Trial 22 finished with value: 3.241916445999455 and parameters: {'n_estimators': 3140, 'max_depth': 15, 'min_child_weight': 65, 'gamma': 2, 'learning_rate': 0.008, 'colsample_bytree': 0.9943109028217706, 'lambda': 1.5253076428611883, 'alpha': 4.116764710668548, 'subsample': 0.6}. Best is trial 14 with value: 3.1019215716403106.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 00:05:12,136] Trial 23 finished with value: 3.3792751821820817 and parameters: {'n_estimators': 3081, 'max_depth': 16, 'min_child_weight': 70, 'gamma': 2, 'learning_rate': 0.008, 'colsample_bytree': 0.9433811793954677, 'lambda': 7.699546391506745, 'alpha': 5.1142802991312415, 'subsample': 0.6}. Best is trial 14 with value: 3.1019215716403106.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 00:07:04,055] Trial 24 finished with value: 4.126182987615646 and parameters: {'n_estimators': 3129, 'max_depth': 14, 'min_child_weight': 117, 'gamma': 2, 'learning_rate': 0.008, 'colsample_bytree': 0.894260160720079, 'lambda': 0.9223547111126581, 'alpha': 11.472741091478115, 'subsample': 0.6}. Best is trial 14 with value: 3.1019215716403106.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 00:13:48,815] Trial 25 finished with value: 3.5537918107841433 and parameters: {'n_estimators': 3842, 'max_depth': 12, 'min_child_weight': 25, 'gamma': 2, 'learning_rate': 0.008, 'colsample_bytree': 0.9376700775191501, 'lambda': 2.700570826620145, 'alpha': 3.660216281086093, 'subsample': 0.8}. Best is trial 14 with value: 3.1019215716403106.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 00:20:47,542] Trial 26 finished with value: 3.4698594495006367 and parameters: {'n_estimators': 3340, 'max_depth': 15, 'min_child_weight': 67, 'gamma': 2, 'learning_rate': 0.008, 'colsample_bytree': 0.9535328040413952, 'lambda': 0.4822772808446459, 'alpha': 4.932077653292282, 'subsample': 0.6}. Best is trial 14 with value: 3.1019215716403106.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 00:33:56,617] Trial 27 finished with value: 3.058184595276404 and parameters: {'n_estimators': 2803, 'max_depth': 16, 'min_child_weight': 7, 'gamma': 2, 'learning_rate': 0.014, 'colsample_bytree': 0.9997367909773146, 'lambda': 0.9842595503830334, 'alpha': 6.1448108106688455, 'subsample': 0.6}. Best is trial 27 with value: 3.058184595276404.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 00:43:12,511] Trial 28 finished with value: 3.972562551477864 and parameters: {'n_estimators': 2347, 'max_depth': 16, 'min_child_weight': 15, 'gamma': 2, 'learning_rate': 0.014, 'colsample_bytree': 0.9056807622100718, 'lambda': 0.7568101375715816, 'alpha': 6.08902673773777, 'subsample': 0.8}. Best is trial 27 with value: 3.058184595276404.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 00:50:56,928] Trial 29 finished with value: 3.830782970875209 and parameters: {'n_estimators': 4263, 'max_depth': 12, 'min_child_weight': 29, 'gamma': 2, 'learning_rate': 0.014, 'colsample_bytree': 0.8697349651990836, 'lambda': 0.19918013689660788, 'alpha': 10.905460431615692, 'subsample': 0.8}. Best is trial 27 with value: 3.058184595276404.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 01:00:09,332] Trial 30 finished with value: 4.054082897180974 and parameters: {'n_estimators': 2707, 'max_depth': 16, 'min_child_weight': 3, 'gamma': 3, 'learning_rate': 0.014, 'colsample_bytree': 0.9601057711092127, 'lambda': 0.4172439278805824, 'alpha': 5.950792808673451, 'subsample': 0.7}. Best is trial 27 with value: 3.058184595276404.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 01:06:37,779] Trial 31 finished with value: 3.2616981608808033 and parameters: {'n_estimators': 3257, 'max_depth': 15, 'min_child_weight': 57, 'gamma': 2, 'learning_rate': 0.01, 'colsample_bytree': 0.9767853784996542, 'lambda': 2.1965173810736576, 'alpha': 3.9391962994047898, 'subsample': 0.6}. Best is trial 27 with value: 3.058184595276404.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 01:07:22,019] Trial 32 finished with value: 3.7479572367840794 and parameters: {'n_estimators': 3824, 'max_depth': 14, 'min_child_weight': 108, 'gamma': 2, 'learning_rate': 0.02, 'colsample_bytree': 0.9969340108346055, 'lambda': 1.3331000210450215, 'alpha': 4.495733987616713, 'subsample': 0.6}. Best is trial 27 with value: 3.058184595276404.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 01:12:40,845] Trial 33 finished with value: 3.219035776990805 and parameters: {'n_estimators': 2886, 'max_depth': 15, 'min_child_weight': 72, 'gamma': 2, 'learning_rate': 0.014, 'colsample_bytree': 0.9620892705407418, 'lambda': 4.952735153564199, 'alpha': 3.3319018624229235, 'subsample': 0.6}. Best is trial 27 with value: 3.058184595276404.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 01:16:59,249] Trial 34 finished with value: 3.2404589028317887 and parameters: {'n_estimators': 2389, 'max_depth': 16, 'min_child_weight': 81, 'gamma': 2, 'learning_rate': 0.014, 'colsample_bytree': 0.9607814636989576, 'lambda': 4.607112627227427, 'alpha': 2.836863405672447, 'subsample': 0.6}. Best is trial 27 with value: 3.058184595276404.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 01:22:18,173] Trial 35 finished with value: 3.6372867390705026 and parameters: {'n_estimators': 2707, 'max_depth': 13, 'min_child_weight': 36, 'gamma': 1, 'learning_rate': 0.014, 'colsample_bytree': 0.9259517990028188, 'lambda': 3.355720968408688, 'alpha': 7.1519965684011035, 'subsample': 0.8}. Best is trial 27 with value: 3.058184595276404.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 01:26:52,995] Trial 36 finished with value: 3.47256216526213 and parameters: {'n_estimators': 2840, 'max_depth': 14, 'min_child_weight': 154, 'gamma': 2, 'learning_rate': 0.012, 'colsample_bytree': 0.9629901626864984, 'lambda': 5.808642435044817, 'alpha': 2.0785756932104906, 'subsample': 0.6}. Best is trial 27 with value: 3.058184595276404.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 01:29:50,464] Trial 37 finished with value: 3.639402324285758 and parameters: {'n_estimators': 1533, 'max_depth': 16, 'min_child_weight': 128, 'gamma': 2, 'learning_rate': 0.014, 'colsample_bytree': 0.8797064878895375, 'lambda': 2.388934654211494, 'alpha': 3.5114459193565333, 'subsample': 0.6}. Best is trial 27 with value: 3.058184595276404.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 01:34:44,956] Trial 38 finished with value: 3.509195029299121 and parameters: {'n_estimators': 2919, 'max_depth': 13, 'min_child_weight': 55, 'gamma': 1, 'learning_rate': 0.02, 'colsample_bytree': 0.9118518728806307, 'lambda': 8.838852380581795, 'alpha': 2.5505772659360395, 'subsample': 0.8}. Best is trial 27 with value: 3.058184595276404.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 01:35:53,367] Trial 39 finished with value: 3.82989257594549 and parameters: {'n_estimators': 2495, 'max_depth': 15, 'min_child_weight': 200, 'gamma': 2, 'learning_rate': 0.012, 'colsample_bytree': 0.9701462391487422, 'lambda': 3.7795853588281956, 'alpha': 5.193610461593147, 'subsample': 0.7}. Best is trial 27 with value: 3.058184595276404.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 01:36:52,419] Trial 40 finished with value: 3.9269076903210762 and parameters: {'n_estimators': 3593, 'max_depth': 15, 'min_child_weight': 239, 'gamma': 2, 'learning_rate': 0.016, 'colsample_bytree': 0.9416989151466005, 'lambda': 0.9868051769675065, 'alpha': 9.987905576973205, 'subsample': 0.6}. Best is trial 27 with value: 3.058184595276404.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 01:40:46,006] Trial 41 finished with value: 3.2636256925752583 and parameters: {'n_estimators': 2158, 'max_depth': 16, 'min_child_weight': 81, 'gamma': 2, 'learning_rate': 0.014, 'colsample_bytree': 0.9570221807954529, 'lambda': 5.0670642482901265, 'alpha': 2.791071911488445, 'subsample': 0.6}. Best is trial 27 with value: 3.058184595276404.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 01:48:40,329] Trial 42 finished with value: 3.287211920956606 and parameters: {'n_estimators': 2502, 'max_depth': 16, 'min_child_weight': 17, 'gamma': 2, 'learning_rate': 0.014, 'colsample_bytree': 0.9712129644322685, 'lambda': 2.982407621675906, 'alpha': 3.4650558830404066, 'subsample': 0.6}. Best is trial 27 with value: 3.058184595276404.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 01:52:36,954] Trial 43 finished with value: 3.4527292612173244 and parameters: {'n_estimators': 2232, 'max_depth': 16, 'min_child_weight': 78, 'gamma': 2, 'learning_rate': 0.014, 'colsample_bytree': 0.9049675888117376, 'lambda': 5.462326259952491, 'alpha': 1.7238403111545286, 'subsample': 1.0}. Best is trial 27 with value: 3.058184595276404.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 01:57:30,627] Trial 44 finished with value: 3.2395093100076924 and parameters: {'n_estimators': 2891, 'max_depth': 16, 'min_child_weight': 116, 'gamma': 1, 'learning_rate': 0.018, 'colsample_bytree': 0.97668724011185, 'lambda': 9.378555341499647, 'alpha': 2.6657152845762293, 'subsample': 0.6}. Best is trial 27 with value: 3.058184595276404.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 02:02:58,909] Trial 45 finished with value: 3.301066280148706 and parameters: {'n_estimators': 3445, 'max_depth': 14, 'min_child_weight': 145, 'gamma': 1, 'learning_rate': 0.018, 'colsample_bytree': 0.9779750713017644, 'lambda': 9.361471956913325, 'alpha': 2.418545705124296, 'subsample': 0.6}. Best is trial 27 with value: 3.058184595276404.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 02:10:41,084] Trial 46 finished with value: 3.5040965623357354 and parameters: {'n_estimators': 4859, 'max_depth': 10, 'min_child_weight': 118, 'gamma': 1, 'learning_rate': 0.018, 'colsample_bytree': 0.9973432701889722, 'lambda': 3.05175695161018, 'alpha': 4.257105212135133, 'subsample': 1.0}. Best is trial 27 with value: 3.058184595276404.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 02:16:10,136] Trial 47 finished with value: 3.3436523849758393 and parameters: {'n_estimators': 2918, 'max_depth': 15, 'min_child_weight': 61, 'gamma': 1, 'learning_rate': 0.018, 'colsample_bytree': 0.9230953422510706, 'lambda': 0.7009541168088005, 'alpha': 3.2476723815936315, 'subsample': 0.6}. Best is trial 27 with value: 3.058184595276404.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 02:25:15,655] Trial 48 finished with value: 3.825324733476169 and parameters: {'n_estimators': 3969, 'max_depth': 16, 'min_child_weight': 96, 'gamma': 1, 'learning_rate': 0.01, 'colsample_bytree': 0.8820643911367634, 'lambda': 1.0678517387399995, 'alpha': 7.794132924479348, 'subsample': 0.8}. Best is trial 27 with value: 3.058184595276404.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 02:25:45,869] Trial 49 finished with value: 5.141063729645127 and parameters: {'n_estimators': 3675, 'max_depth': 8, 'min_child_weight': 40, 'gamma': 3, 'learning_rate': 0.018, 'colsample_bytree': 0.9488869848816582, 'lambda': 2.160928508702032, 'alpha': 5.8098692124938776, 'subsample': 0.6}. Best is trial 27 with value: 3.058184595276404.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 02:35:11,812] Trial 50 finished with value: 3.0602620040752164 and parameters: {'n_estimators': 4173, 'max_depth': 15, 'min_child_weight': 20, 'gamma': 1, 'learning_rate': 0.016, 'colsample_bytree': 0.9771144185915046, 'lambda': 6.26629462555195, 'alpha': 1.693610262055707, 'subsample': 0.6}. Best is trial 27 with value: 3.058184595276404.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 02:51:27,543] Trial 51 finished with value: 2.9113334863770395 and parameters: {'n_estimators': 4200, 'max_depth': 15, 'min_child_weight': 2, 'gamma': 1, 'learning_rate': 0.016, 'colsample_bytree': 0.9785974827316972, 'lambda': 6.815620060105535, 'alpha': 1.7305211976288557, 'subsample': 0.6}. Best is trial 51 with value: 2.9113334863770395.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 03:07:53,713] Trial 52 finished with value: 3.1834483731667924 and parameters: {'n_estimators': 4238, 'max_depth': 15, 'min_child_weight': 1, 'gamma': 1, 'learning_rate': 0.016, 'colsample_bytree': 0.9768031885799611, 'lambda': 6.741353391348256, 'alpha': 1.4363974799091883, 'subsample': 0.6}. Best is trial 51 with value: 2.9113334863770395.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 03:20:01,707] Trial 53 finished with value: 2.8891216431118614 and parameters: {'n_estimators': 4161, 'max_depth': 14, 'min_child_weight': 4, 'gamma': 1, 'learning_rate': 0.016, 'colsample_bytree': 0.9791877177949869, 'lambda': 6.686614524195807, 'alpha': 1.3795755911689607, 'subsample': 0.6}. Best is trial 53 with value: 2.8891216431118614.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 03:29:27,290] Trial 54 finished with value: 3.2170998161444704 and parameters: {'n_estimators': 4287, 'max_depth': 13, 'min_child_weight': 5, 'gamma': 1, 'learning_rate': 0.016, 'colsample_bytree': 0.930213322269397, 'lambda': 6.996959521508372, 'alpha': 1.391381163133831, 'subsample': 0.6}. Best is trial 53 with value: 2.8891216431118614.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 03:39:03,146] Trial 55 finished with value: 2.9003732019095865 and parameters: {'n_estimators': 4612, 'max_depth': 14, 'min_child_weight': 20, 'gamma': 1, 'learning_rate': 0.016, 'colsample_bytree': 0.9774471566911084, 'lambda': 6.398954302049892, 'alpha': 1.711754267801086, 'subsample': 0.7}. Best is trial 53 with value: 2.8891216431118614.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 03:48:35,367] Trial 56 finished with value: 3.1475845241872107 and parameters: {'n_estimators': 4654, 'max_depth': 14, 'min_child_weight': 21, 'gamma': 1, 'learning_rate': 0.016, 'colsample_bytree': 0.9170710794575189, 'lambda': 3.9653882995500855, 'alpha': 1.8236383856191933, 'subsample': 0.7}. Best is trial 53 with value: 2.8891216431118614.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 03:58:51,960] Trial 57 finished with value: 3.261025913201146 and parameters: {'n_estimators': 4486, 'max_depth': 14, 'min_child_weight': 12, 'gamma': 1, 'learning_rate': 0.016, 'colsample_bytree': 0.9440571512336645, 'lambda': 9.981270824793421, 'alpha': 1.251846281452424, 'subsample': 0.7}. Best is trial 53 with value: 2.8891216431118614.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 04:05:48,017] Trial 58 finished with value: 3.0457415107620385 and parameters: {'n_estimators': 4114, 'max_depth': 13, 'min_child_weight': 45, 'gamma': 1, 'learning_rate': 0.016, 'colsample_bytree': 0.9995251589360075, 'lambda': 1.8760743952498224, 'alpha': 1.5951848150997285, 'subsample': 0.7}. Best is trial 53 with value: 2.8891216431118614.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 04:13:09,118] Trial 59 finished with value: 3.324146484132832 and parameters: {'n_estimators': 4139, 'max_depth': 13, 'min_child_weight': 28, 'gamma': 1, 'learning_rate': 0.016, 'colsample_bytree': 0.9760516015339671, 'lambda': 6.707797365376232, 'alpha': 1.8004301411117007, 'subsample': 0.7}. Best is trial 53 with value: 2.8891216431118614.\n"
     ]
    }
   ],
   "source": [
    "# 3, 4\n",
    "preds = np.array([]) \n",
    "best_params = {}\n",
    "best_values = {}  # New dictionary to store the best values\n",
    "with open('best_params_values_0804_34.txt', 'w') as f:\n",
    "    # Select the data for the current num\n",
    "    num_data = train.copy()\n",
    "\n",
    "    # Combine 'hour', 'day', 'week' to a new feature as stratified target\n",
    "    #num_data['stratified_target'] = num_data['hour'].astype(str) + '_' + num_data['day'].astype(str) + '_' + num_data['week'].astype(str) + '_' + num_data['month'].astype(str)\n",
    "    num_data['stratified_target'] = num_data['hour'].astype(str) + '_' + num_data['day'].astype(str)\n",
    "\n",
    "    # Split the data into training and validation set\n",
    "    train_df, val_df = train_test_split(num_data, test_size=0.2, stratify=num_data['stratified_target'], random_state=953)\n",
    "\n",
    "    # Drop the temporary feature\n",
    "    train_df = train_df.drop(columns='stratified_target')\n",
    "    val_df = val_df.drop(columns='stratified_target')\n",
    "\n",
    "    # Validation set에서 day 값이 3, 4이 아닌 행을 training set에 추가\n",
    "    train_df = pd.concat([train_df, val_df[~val_df['day'].isin([3, 4])]])\n",
    "\n",
    "    # Validation set에서 day 값이 3, 4인 행만 남기기\n",
    "    val_df = val_df[val_df['day'].isin([3, 4])]\n",
    "\n",
    "    y_train = train_df['power']\n",
    "    y_val = val_df['power']\n",
    "\n",
    "    x_train, x_test = train_df.drop(['date_time'],axis=1), test.drop(['date_time'],axis=1)\n",
    "    x_val = val_df.drop(['date_time'],axis=1)\n",
    "\n",
    "    x_train.drop(['power'],axis=1,inplace=True)\n",
    "    x_val.drop(['power'],axis=1,inplace=True)\n",
    "\n",
    "    x_test = x_test[x_train.columns]\n",
    "\n",
    "    study = optuna.create_study(direction='minimize', sampler=TPESampler())\n",
    "    study.optimize(lambda trial: objective_xgb(trial, x_train, y_train, x_val, y_val), n_trials=60)\n",
    "    param = study.best_trial.params\n",
    "    best_params = param\n",
    "    best_values = study.best_trial.value  # Store the best value\n",
    "    f.write(f'Best Params: {best_params}, \\nBest Values: {best_values}\\n\\n')\n",
    "    f.flush()\n",
    "    xgb = XGBRegressor(**param, tree_method='gpu_hist', gpu_id=0, seed=953)\n",
    "    alpha_value2 = xgb.get_params()['alpha']\n",
    "    xgb.set_params(**{'objective':weighted_mse(alpha_value2)})\n",
    "    ##근데 저렇게 validation 하면 학습 셋도 좀 이상해지는데 이게 맞나?0.4\n",
    "    xgb.fit(x_train, y_train)\n",
    "    y_pred = xgb.predict(x_test)\n",
    "    preds_34 = np.append(preds, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-04 04:25:06,594] A new study created in memory with name: no-name-0a88a614-6636-44b2-af5e-2d2d4cb3d67c\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 04:31:26,602] Trial 0 finished with value: 3.746827824488308 and parameters: {'n_estimators': 3641, 'max_depth': 14, 'min_child_weight': 96, 'gamma': 1, 'learning_rate': 0.014, 'colsample_bytree': 0.8790021118384332, 'lambda': 3.0373283709940604, 'alpha': 3.7632598561214405, 'subsample': 0.6}. Best is trial 0 with value: 3.746827824488308.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 04:38:14,681] Trial 1 finished with value: 4.297214389581846 and parameters: {'n_estimators': 4411, 'max_depth': 8, 'min_child_weight': 282, 'gamma': 1, 'learning_rate': 0.016, 'colsample_bytree': 0.9901883736711299, 'lambda': 0.2512285068399285, 'alpha': 3.676276793550422, 'subsample': 1.0}. Best is trial 0 with value: 3.746827824488308.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 04:53:36,247] Trial 2 finished with value: 9.362029209513004 and parameters: {'n_estimators': 4457, 'max_depth': 16, 'min_child_weight': 48, 'gamma': 1, 'learning_rate': 0.018, 'colsample_bytree': 0.7483512746315832, 'lambda': 0.012414676354168453, 'alpha': 44.61923053429754, 'subsample': 0.8}. Best is trial 0 with value: 3.746827824488308.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 04:53:44,667] Trial 3 finished with value: 117.07084714581848 and parameters: {'n_estimators': 4895, 'max_depth': 11, 'min_child_weight': 79, 'gamma': 3, 'learning_rate': 0.016, 'colsample_bytree': 0.5726019174248173, 'lambda': 0.004814200023230631, 'alpha': 59.68450353703684, 'subsample': 1.0}. Best is trial 0 with value: 3.746827824488308.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 04:56:40,677] Trial 4 finished with value: 4.361228703526399 and parameters: {'n_estimators': 1284, 'max_depth': 16, 'min_child_weight': 111, 'gamma': 1, 'learning_rate': 0.012, 'colsample_bytree': 0.8481181411329454, 'lambda': 0.024290448070322594, 'alpha': 2.595209698973573, 'subsample': 1.0}. Best is trial 0 with value: 3.746827824488308.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 05:03:29,862] Trial 5 finished with value: 3.516539670327766 and parameters: {'n_estimators': 4176, 'max_depth': 14, 'min_child_weight': 196, 'gamma': 3, 'learning_rate': 0.018, 'colsample_bytree': 0.6657592427214144, 'lambda': 0.0010517554650326317, 'alpha': 2.3757705411355063, 'subsample': 0.8}. Best is trial 5 with value: 3.516539670327766.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 05:08:10,024] Trial 6 finished with value: 5.482722865308447 and parameters: {'n_estimators': 1906, 'max_depth': 14, 'min_child_weight': 229, 'gamma': 1, 'learning_rate': 0.012, 'colsample_bytree': 0.9132231485981843, 'lambda': 0.11540978802991023, 'alpha': 92.54958961506283, 'subsample': 0.6}. Best is trial 5 with value: 3.516539670327766.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 05:09:06,930] Trial 7 finished with value: 4.55727473320811 and parameters: {'n_estimators': 529, 'max_depth': 14, 'min_child_weight': 290, 'gamma': 1, 'learning_rate': 0.018, 'colsample_bytree': 0.79068530183742, 'lambda': 0.00919610586362756, 'alpha': 3.00126439874213, 'subsample': 0.6}. Best is trial 5 with value: 3.516539670327766.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 05:09:38,062] Trial 8 finished with value: 14.077159964577632 and parameters: {'n_estimators': 4738, 'max_depth': 12, 'min_child_weight': 92, 'gamma': 1, 'learning_rate': 0.018, 'colsample_bytree': 0.5615784107580404, 'lambda': 0.0012151312628991807, 'alpha': 29.707149698721878, 'subsample': 1.0}. Best is trial 5 with value: 3.516539670327766.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 05:14:39,939] Trial 9 finished with value: 10.598043840025156 and parameters: {'n_estimators': 2825, 'max_depth': 11, 'min_child_weight': 12, 'gamma': 3, 'learning_rate': 0.012, 'colsample_bytree': 0.5459063327250654, 'lambda': 0.001510738425999368, 'alpha': 20.102557751701813, 'subsample': 0.7}. Best is trial 5 with value: 3.516539670327766.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 05:20:09,384] Trial 10 finished with value: 4.19724340496147 and parameters: {'n_estimators': 3427, 'max_depth': 9, 'min_child_weight': 190, 'gamma': 2, 'learning_rate': 0.008, 'colsample_bytree': 0.6668855942675689, 'lambda': 0.0011964295224880575, 'alpha': 1.0662446850077043, 'subsample': 0.8}. Best is trial 5 with value: 3.516539670327766.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 05:26:37,856] Trial 11 finished with value: 4.503371084806321 and parameters: {'n_estimators': 3671, 'max_depth': 14, 'min_child_weight': 153, 'gamma': 2, 'learning_rate': 0.014, 'colsample_bytree': 0.6934509584057101, 'lambda': 3.947185006909685, 'alpha': 7.3418183959301, 'subsample': 0.6}. Best is trial 5 with value: 3.516539670327766.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 05:27:15,397] Trial 12 finished with value: 5.0623986494242335 and parameters: {'n_estimators': 3672, 'max_depth': 13, 'min_child_weight': 160, 'gamma': 3, 'learning_rate': 0.02, 'colsample_bytree': 0.8984650787195692, 'lambda': 8.996123701189875, 'alpha': 7.366918208651045, 'subsample': 0.8}. Best is trial 5 with value: 3.516539670327766.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 05:31:57,042] Trial 13 finished with value: 3.827163233090907 and parameters: {'n_estimators': 2911, 'max_depth': 15, 'min_child_weight': 222, 'gamma': 2, 'learning_rate': 0.014, 'colsample_bytree': 0.6488284212582549, 'lambda': 0.7534180467852537, 'alpha': 1.225183105018363, 'subsample': 0.7}. Best is trial 5 with value: 3.516539670327766.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 05:38:52,205] Trial 14 finished with value: 4.518361811689955 and parameters: {'n_estimators': 4006, 'max_depth': 12, 'min_child_weight': 119, 'gamma': 3, 'learning_rate': 0.01, 'colsample_bytree': 0.7872526465332075, 'lambda': 0.03606178974989682, 'alpha': 11.35214494839583, 'subsample': 0.6}. Best is trial 5 with value: 3.516539670327766.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 05:42:56,617] Trial 15 finished with value: 3.861417502097961 and parameters: {'n_estimators': 2485, 'max_depth': 13, 'min_child_weight': 196, 'gamma': 2, 'learning_rate': 0.014, 'colsample_bytree': 0.7227757061885569, 'lambda': 1.1022580537712365, 'alpha': 4.021749551953693, 'subsample': 0.8}. Best is trial 5 with value: 3.516539670327766.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 05:49:12,655] Trial 16 finished with value: 4.428036554738169 and parameters: {'n_estimators': 3357, 'max_depth': 15, 'min_child_weight': 53, 'gamma': 2, 'learning_rate': 0.01, 'colsample_bytree': 0.6203338724971621, 'lambda': 0.07147721200271916, 'alpha': 1.8387420002552248, 'subsample': 0.6}. Best is trial 5 with value: 3.516539670327766.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 05:56:02,660] Trial 17 finished with value: 4.223162208235398 and parameters: {'n_estimators': 4117, 'max_depth': 10, 'min_child_weight': 243, 'gamma': 3, 'learning_rate': 0.02, 'colsample_bytree': 0.7979721236095825, 'lambda': 0.2828268425408572, 'alpha': 5.017799692002186, 'subsample': 0.8}. Best is trial 5 with value: 3.516539670327766.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 05:59:34,309] Trial 18 finished with value: 4.161012681441127 and parameters: {'n_estimators': 2097, 'max_depth': 13, 'min_child_weight': 129, 'gamma': 2, 'learning_rate': 0.008, 'colsample_bytree': 0.7079897582378154, 'lambda': 2.034010696397696, 'alpha': 2.0440134680647737, 'subsample': 0.7}. Best is trial 5 with value: 3.516539670327766.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 06:05:08,476] Trial 19 finished with value: 3.7938818474309897 and parameters: {'n_estimators': 3301, 'max_depth': 15, 'min_child_weight': 173, 'gamma': 3, 'learning_rate': 0.018, 'colsample_bytree': 0.5134355506402675, 'lambda': 0.0038088532398787233, 'alpha': 1.6801713856284355, 'subsample': 0.8}. Best is trial 5 with value: 3.516539670327766.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 06:11:45,145] Trial 20 finished with value: 4.2018655643067815 and parameters: {'n_estimators': 4125, 'max_depth': 12, 'min_child_weight': 252, 'gamma': 2, 'learning_rate': 0.014, 'colsample_bytree': 0.607868278803358, 'lambda': 9.768349574825226, 'alpha': 5.082562677076562, 'subsample': 0.6}. Best is trial 5 with value: 3.516539670327766.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 06:17:16,203] Trial 21 finished with value: 3.840024484141903 and parameters: {'n_estimators': 3297, 'max_depth': 15, 'min_child_weight': 179, 'gamma': 3, 'learning_rate': 0.018, 'colsample_bytree': 0.5052883471944845, 'lambda': 0.003586767677155219, 'alpha': 1.6684614677592955, 'subsample': 0.8}. Best is trial 5 with value: 3.516539670327766.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 06:22:27,988] Trial 22 finished with value: 3.6032199165987397 and parameters: {'n_estimators': 2964, 'max_depth': 15, 'min_child_weight': 142, 'gamma': 3, 'learning_rate': 0.018, 'colsample_bytree': 0.6624674449928982, 'lambda': 0.0035461993927853683, 'alpha': 2.766860386373234, 'subsample': 0.8}. Best is trial 5 with value: 3.516539670327766.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 06:27:06,498] Trial 23 finished with value: 3.6041256227005034 and parameters: {'n_estimators': 2528, 'max_depth': 16, 'min_child_weight': 133, 'gamma': 3, 'learning_rate': 0.018, 'colsample_bytree': 0.6569266351116806, 'lambda': 0.002482857862720612, 'alpha': 2.6463280740536725, 'subsample': 0.8}. Best is trial 5 with value: 3.516539670327766.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 06:31:22,973] Trial 24 finished with value: 3.689279658626293 and parameters: {'n_estimators': 2320, 'max_depth': 16, 'min_child_weight': 132, 'gamma': 3, 'learning_rate': 0.018, 'colsample_bytree': 0.6598921728093392, 'lambda': 0.002241036274829819, 'alpha': 2.4672750582862673, 'subsample': 0.8}. Best is trial 5 with value: 3.516539670327766.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 06:33:50,525] Trial 25 finished with value: 4.067462820205755 and parameters: {'n_estimators': 1459, 'max_depth': 16, 'min_child_weight': 201, 'gamma': 3, 'learning_rate': 0.018, 'colsample_bytree': 0.6219262859507051, 'lambda': 0.0010646509770663812, 'alpha': 1.0136888919948894, 'subsample': 0.8}. Best is trial 5 with value: 3.516539670327766.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 06:38:36,455] Trial 26 finished with value: 3.9314184116678157 and parameters: {'n_estimators': 2732, 'max_depth': 15, 'min_child_weight': 158, 'gamma': 3, 'learning_rate': 0.018, 'colsample_bytree': 0.6883608020096367, 'lambda': 0.0024917413017383513, 'alpha': 2.4917592968607205, 'subsample': 0.8}. Best is trial 5 with value: 3.516539670327766.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 06:41:41,376] Trial 27 finished with value: 3.549227612564925 and parameters: {'n_estimators': 1734, 'max_depth': 16, 'min_child_weight': 141, 'gamma': 3, 'learning_rate': 0.018, 'colsample_bytree': 0.7343942164138981, 'lambda': 0.008038135910832526, 'alpha': 1.4818346783338125, 'subsample': 0.8}. Best is trial 5 with value: 3.516539670327766.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 06:44:21,608] Trial 28 finished with value: 4.009355400652164 and parameters: {'n_estimators': 1631, 'max_depth': 14, 'min_child_weight': 210, 'gamma': 3, 'learning_rate': 0.018, 'colsample_bytree': 0.7345817872934085, 'lambda': 0.007106097002773759, 'alpha': 1.4742510297065, 'subsample': 0.8}. Best is trial 5 with value: 3.516539670327766.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 06:46:05,990] Trial 29 finished with value: 4.468797045703219 and parameters: {'n_estimators': 884, 'max_depth': 15, 'min_child_weight': 74, 'gamma': 3, 'learning_rate': 0.018, 'colsample_bytree': 0.7004614512740682, 'lambda': 0.015004166827590985, 'alpha': 1.4122025221767356, 'subsample': 0.8}. Best is trial 5 with value: 3.516539670327766.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 06:49:13,057] Trial 30 finished with value: 4.149503740431602 and parameters: {'n_estimators': 1855, 'max_depth': 13, 'min_child_weight': 265, 'gamma': 3, 'learning_rate': 0.008, 'colsample_bytree': 0.7709783436115095, 'lambda': 0.006143662505291357, 'alpha': 1.9887257038259158, 'subsample': 0.8}. Best is trial 5 with value: 3.516539670327766.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 06:53:58,505] Trial 31 finished with value: 3.6606839527671866 and parameters: {'n_estimators': 2555, 'max_depth': 16, 'min_child_weight': 139, 'gamma': 3, 'learning_rate': 0.018, 'colsample_bytree': 0.6573468809908833, 'lambda': 0.0025142825326999133, 'alpha': 3.0708133822087667, 'subsample': 0.8}. Best is trial 5 with value: 3.516539670327766.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 06:56:27,490] Trial 32 finished with value: 4.5133126206471355 and parameters: {'n_estimators': 1108, 'max_depth': 16, 'min_child_weight': 105, 'gamma': 3, 'learning_rate': 0.016, 'colsample_bytree': 0.7518682803332557, 'lambda': 0.0023423691388158334, 'alpha': 3.3135670957920644, 'subsample': 0.8}. Best is trial 5 with value: 3.516539670327766.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 07:01:40,050] Trial 33 finished with value: 3.5778464744597125 and parameters: {'n_estimators': 3054, 'max_depth': 15, 'min_child_weight': 173, 'gamma': 3, 'learning_rate': 0.018, 'colsample_bytree': 0.6752648292436183, 'lambda': 0.0054679429646786555, 'alpha': 2.1494636921389665, 'subsample': 0.8}. Best is trial 5 with value: 3.516539670327766.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 07:06:36,036] Trial 34 finished with value: 3.80127492377197 and parameters: {'n_estimators': 3079, 'max_depth': 14, 'min_child_weight': 172, 'gamma': 3, 'learning_rate': 0.018, 'colsample_bytree': 0.7272189959647045, 'lambda': 0.005833255997350774, 'alpha': 1.3290448045548946, 'subsample': 0.8}. Best is trial 5 with value: 3.516539670327766.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 07:10:19,467] Trial 35 finished with value: 3.8319037883947296 and parameters: {'n_estimators': 2158, 'max_depth': 15, 'min_child_weight': 151, 'gamma': 3, 'learning_rate': 0.016, 'colsample_bytree': 0.5979218199933025, 'lambda': 0.013921881353018901, 'alpha': 2.0171203627655925, 'subsample': 1.0}. Best is trial 5 with value: 3.516539670327766.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 07:16:31,827] Trial 36 finished with value: 3.7469080843688967 and parameters: {'n_estimators': 3880, 'max_depth': 14, 'min_child_weight': 218, 'gamma': 3, 'learning_rate': 0.018, 'colsample_bytree': 0.677874363574792, 'lambda': 0.009300085083785116, 'alpha': 1.0028074641653955, 'subsample': 0.7}. Best is trial 5 with value: 3.516539670327766.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 07:24:45,498] Trial 37 finished with value: 3.4316355636598335 and parameters: {'n_estimators': 4656, 'max_depth': 16, 'min_child_weight': 182, 'gamma': 2, 'learning_rate': 0.02, 'colsample_bytree': 0.71370690170268, 'lambda': 0.0044277041822000625, 'alpha': 3.5580177324872038, 'subsample': 0.8}. Best is trial 37 with value: 3.4316355636598335.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 07:32:46,548] Trial 38 finished with value: 4.317652598112425 and parameters: {'n_estimators': 4523, 'max_depth': 16, 'min_child_weight': 186, 'gamma': 2, 'learning_rate': 0.02, 'colsample_bytree': 0.7483892413224629, 'lambda': 0.019978321842111228, 'alpha': 3.91222873167394, 'subsample': 1.0}. Best is trial 37 with value: 3.4316355636598335.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 07:40:25,550] Trial 39 finished with value: 4.02411318776388 and parameters: {'n_estimators': 4909, 'max_depth': 8, 'min_child_weight': 229, 'gamma': 2, 'learning_rate': 0.02, 'colsample_bytree': 0.7070680560066367, 'lambda': 0.008134892421175825, 'alpha': 2.2062574222958506, 'subsample': 0.8}. Best is trial 37 with value: 3.4316355636598335.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 07:47:46,877] Trial 40 finished with value: 3.6506593157221157 and parameters: {'n_estimators': 4515, 'max_depth': 16, 'min_child_weight': 272, 'gamma': 2, 'learning_rate': 0.02, 'colsample_bytree': 0.8176474396688898, 'lambda': 0.005156071583702331, 'alpha': 1.523003063884524, 'subsample': 0.8}. Best is trial 37 with value: 3.4316355636598335.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 07:55:11,755] Trial 41 finished with value: 3.7765244505489166 and parameters: {'n_estimators': 4262, 'max_depth': 15, 'min_child_weight': 167, 'gamma': 2, 'learning_rate': 0.012, 'colsample_bytree': 0.632170456629555, 'lambda': 0.001571243404523563, 'alpha': 2.9334671276811832, 'subsample': 0.8}. Best is trial 37 with value: 3.4316355636598335.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 08:00:22,920] Trial 42 finished with value: 3.8962654673574586 and parameters: {'n_estimators': 3081, 'max_depth': 14, 'min_child_weight': 143, 'gamma': 3, 'learning_rate': 0.018, 'colsample_bytree': 0.6744133925490857, 'lambda': 0.004058556294526847, 'alpha': 2.209229200259028, 'subsample': 0.8}. Best is trial 37 with value: 3.4316355636598335.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 08:09:20,773] Trial 43 finished with value: 3.8952759030229727 and parameters: {'n_estimators': 4682, 'max_depth': 15, 'min_child_weight': 87, 'gamma': 3, 'learning_rate': 0.01, 'colsample_bytree': 0.6395379856082603, 'lambda': 0.010420991134788168, 'alpha': 3.541294204093414, 'subsample': 0.8}. Best is trial 37 with value: 3.4316355636598335.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 08:15:55,155] Trial 44 finished with value: 3.4066492557060584 and parameters: {'n_estimators': 3783, 'max_depth': 16, 'min_child_weight': 114, 'gamma': 1, 'learning_rate': 0.02, 'colsample_bytree': 0.6823966114007199, 'lambda': 0.001082645146927879, 'alpha': 1.2489271688555459, 'subsample': 0.8}. Best is trial 44 with value: 3.4066492557060584.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 08:22:29,949] Trial 45 finished with value: 4.262862797229763 and parameters: {'n_estimators': 3886, 'max_depth': 16, 'min_child_weight': 109, 'gamma': 1, 'learning_rate': 0.02, 'colsample_bytree': 0.7120230617492087, 'lambda': 0.0010317514356676441, 'alpha': 1.2380548919132432, 'subsample': 1.0}. Best is trial 44 with value: 3.4066492557060584.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 08:29:45,026] Trial 46 finished with value: 3.629548401999442 and parameters: {'n_estimators': 4338, 'max_depth': 16, 'min_child_weight': 203, 'gamma': 1, 'learning_rate': 0.02, 'colsample_bytree': 0.6833085770250208, 'lambda': 0.0015557514366225575, 'alpha': 1.6761059918932821, 'subsample': 0.7}. Best is trial 44 with value: 3.4066492557060584.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 08:35:47,783] Trial 47 finished with value: 3.368175117766366 and parameters: {'n_estimators': 3513, 'max_depth': 16, 'min_child_weight': 121, 'gamma': 1, 'learning_rate': 0.02, 'colsample_bytree': 0.7321678700402877, 'lambda': 0.001787418949455651, 'alpha': 1.2002638438755384, 'subsample': 0.8}. Best is trial 47 with value: 3.368175117766366.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 08:42:17,056] Trial 48 finished with value: 4.156195878209004 and parameters: {'n_estimators': 3547, 'max_depth': 16, 'min_child_weight': 64, 'gamma': 1, 'learning_rate': 0.02, 'colsample_bytree': 0.7634504547154938, 'lambda': 0.0017023859792997065, 'alpha': 1.1280415338585728, 'subsample': 0.8}. Best is trial 47 with value: 3.368175117766366.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 08:51:44,483] Trial 49 finished with value: 3.948000288169445 and parameters: {'n_estimators': 3808, 'max_depth': 16, 'min_child_weight': 24, 'gamma': 1, 'learning_rate': 0.02, 'colsample_bytree': 0.7200994187457258, 'lambda': 0.0010188957786561306, 'alpha': 1.2744331625964238, 'subsample': 0.8}. Best is trial 47 with value: 3.368175117766366.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 08:59:07,657] Trial 50 finished with value: 3.9290761544781514 and parameters: {'n_estimators': 4719, 'max_depth': 14, 'min_child_weight': 118, 'gamma': 1, 'learning_rate': 0.02, 'colsample_bytree': 0.7373613948993145, 'lambda': 0.0018729563868978697, 'alpha': 1.6805895893063367, 'subsample': 0.6}. Best is trial 47 with value: 3.368175117766366.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 09:05:57,238] Trial 51 finished with value: 3.7352910518352407 and parameters: {'n_estimators': 4170, 'max_depth': 15, 'min_child_weight': 184, 'gamma': 1, 'learning_rate': 0.02, 'colsample_bytree': 0.6906651690471972, 'lambda': 0.004881548644451909, 'alpha': 1.3719797984109916, 'subsample': 0.8}. Best is trial 47 with value: 3.368175117766366.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 09:12:36,062] Trial 52 finished with value: 3.4586244675965077 and parameters: {'n_estimators': 3614, 'max_depth': 16, 'min_child_weight': 97, 'gamma': 1, 'learning_rate': 0.012, 'colsample_bytree': 0.7323087691660035, 'lambda': 0.001476205560131459, 'alpha': 1.9039885791121245, 'subsample': 0.8}. Best is trial 47 with value: 3.368175117766366.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 09:18:52,971] Trial 53 finished with value: 3.764337058761355 and parameters: {'n_estimators': 3561, 'max_depth': 16, 'min_child_weight': 96, 'gamma': 1, 'learning_rate': 0.012, 'colsample_bytree': 0.7400130007089195, 'lambda': 0.0015087606107121853, 'alpha': 1.1432702071779928, 'subsample': 0.8}. Best is trial 47 with value: 3.368175117766366.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 09:25:57,654] Trial 54 finished with value: 4.120363092830153 and parameters: {'n_estimators': 3965, 'max_depth': 16, 'min_child_weight': 116, 'gamma': 1, 'learning_rate': 0.012, 'colsample_bytree': 0.7704774588759828, 'lambda': 0.002772442812561769, 'alpha': 1.7849192539143537, 'subsample': 0.8}. Best is trial 47 with value: 3.368175117766366.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 09:32:50,933] Trial 55 finished with value: 3.4334068824515453 and parameters: {'n_estimators': 3692, 'max_depth': 16, 'min_child_weight': 76, 'gamma': 1, 'learning_rate': 0.012, 'colsample_bytree': 0.7181997633610959, 'lambda': 0.003308885186012814, 'alpha': 1.5633016473724886, 'subsample': 0.8}. Best is trial 47 with value: 3.368175117766366.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 09:38:51,145] Trial 56 finished with value: 3.6760319888839947 and parameters: {'n_estimators': 3700, 'max_depth': 12, 'min_child_weight': 73, 'gamma': 1, 'learning_rate': 0.012, 'colsample_bytree': 0.7036102229778873, 'lambda': 0.003216103720155075, 'alpha': 1.8614098621589876, 'subsample': 0.7}. Best is trial 47 with value: 3.368175117766366.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 09:44:28,794] Trial 57 finished with value: 3.7713215524316492 and parameters: {'n_estimators': 3439, 'max_depth': 10, 'min_child_weight': 85, 'gamma': 1, 'learning_rate': 0.012, 'colsample_bytree': 0.7184056720386867, 'lambda': 0.0013167779758737857, 'alpha': 1.075801205744282, 'subsample': 1.0}. Best is trial 47 with value: 3.368175117766366.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 09:51:04,231] Trial 58 finished with value: 3.8435090491407595 and parameters: {'n_estimators': 4055, 'max_depth': 11, 'min_child_weight': 51, 'gamma': 1, 'learning_rate': 0.012, 'colsample_bytree': 0.6446231536825195, 'lambda': 0.0019367331154769786, 'alpha': 2.403730581191981, 'subsample': 0.8}. Best is trial 47 with value: 3.368175117766366.\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_46912\\116189032.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1, 100.0),\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-08-04 09:58:40,603] Trial 59 finished with value: 4.965553674839899 and parameters: {'n_estimators': 3255, 'max_depth': 15, 'min_child_weight': 27, 'gamma': 1, 'learning_rate': 0.012, 'colsample_bytree': 0.6954148263411539, 'lambda': 0.001285559966517202, 'alpha': 2.843109102384893, 'subsample': 0.6}. Best is trial 47 with value: 3.368175117766366.\n"
     ]
    }
   ],
   "source": [
    "# 5\n",
    "preds = np.array([]) \n",
    "best_params = {}\n",
    "best_values = {}  # New dictionary to store the best values\n",
    "with open('best_params_values_0804_5.txt', 'w') as f:\n",
    "    # Select the data for the current num\n",
    "    num_data = train.copy()\n",
    "\n",
    "    # Combine 'hour', 'day', 'week' to a new feature as stratified target\n",
    "    #num_data['stratified_target'] = num_data['hour'].astype(str) + '_' + num_data['day'].astype(str) + '_' + num_data['week'].astype(str) + '_' + num_data['month'].astype(str)\n",
    "    num_data['stratified_target'] = num_data['hour'].astype(str) + '_' + num_data['day'].astype(str)\n",
    "\n",
    "    # Split the data into training and validation set\n",
    "    train_df, val_df = train_test_split(num_data, test_size=0.2, stratify=num_data['stratified_target'], random_state=953)\n",
    "\n",
    "    # Drop the temporary feature\n",
    "    train_df = train_df.drop(columns='stratified_target')\n",
    "    val_df = val_df.drop(columns='stratified_target')\n",
    "\n",
    "    # Validation set에서 day 값이 5이 아닌 행을 training set에 추가\n",
    "    train_df = pd.concat([train_df, val_df[~val_df['day'].isin([5])]])\n",
    "\n",
    "    # Validation set에서 day 값이 5인 행만 남기기\n",
    "    val_df = val_df[val_df['day'].isin([5])]\n",
    "\n",
    "    y_train = train_df['power']\n",
    "    y_val = val_df['power']\n",
    "\n",
    "    x_train, x_test = train_df.drop(['date_time'],axis=1), test.drop(['date_time'],axis=1)\n",
    "    x_val = val_df.drop(['date_time'],axis=1)\n",
    "\n",
    "    x_train.drop(['power'],axis=1,inplace=True)\n",
    "    x_val.drop(['power'],axis=1,inplace=True)\n",
    "\n",
    "    x_test = x_test[x_train.columns]\n",
    "\n",
    "    study = optuna.create_study(direction='minimize', sampler=TPESampler())\n",
    "    study.optimize(lambda trial: objective_xgb(trial, x_train, y_train, x_val, y_val), n_trials=60)\n",
    "    param = study.best_trial.params\n",
    "    best_params = param\n",
    "    best_values = study.best_trial.value  # Store the best value\n",
    "    f.write(f'Best Params: {best_params}, \\nBest Values: {best_values}\\n\\n')\n",
    "    f.flush()\n",
    "    xgb = XGBRegressor(**param, tree_method='gpu_hist', gpu_id=0, seed=953)\n",
    "    alpha_value2 = xgb.get_params()['alpha']\n",
    "    xgb.set_params(**{'objective':weighted_mse(alpha_value2)})\n",
    "    ##근데 저렇게 validation 하면 학습 셋도 좀 이상해지는데 이게 맞나?0.4\n",
    "    xgb.fit(x_train, y_train)\n",
    "    y_pred = xgb.predict(x_test)\n",
    "    preds_5 = np.append(preds, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         num_date_time       answer    answer_34     answer_5      date\n",
      "0        1_20220825 00  1948.338623  1949.632446  1947.044800  20220825\n",
      "1        1_20220825 01  1944.844604  1886.484741  2003.204468  20220825\n",
      "2        1_20220825 02  1638.710571  1604.047119  1673.374023  20220825\n",
      "3        1_20220825 03  1560.010986  1502.918579  1617.103394  20220825\n",
      "4        1_20220825 04  1587.396484  1494.666382  1680.126587  20220825\n",
      "...                ...          ...          ...          ...       ...\n",
      "16795  100_20220831 19   913.898285   904.905579   922.890991  20220831\n",
      "16796  100_20220831 20   808.115051   803.022827   813.207275  20220831\n",
      "16797  100_20220831 21   742.103607   741.037842   743.169373  20220831\n",
      "16798  100_20220831 22   661.415100   652.933899   669.896301  20220831\n",
      "16799  100_20220831 23   553.260681   543.016785   563.504578  20220831\n",
      "\n",
      "[16800 rows x 5 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_date_time</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_20220825 00</td>\n",
       "      <td>1949.632446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_20220825 01</td>\n",
       "      <td>1886.484741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_20220825 02</td>\n",
       "      <td>1604.047119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_20220825 03</td>\n",
       "      <td>1502.918579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_20220825 04</td>\n",
       "      <td>1494.666382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16795</th>\n",
       "      <td>100_20220831 19</td>\n",
       "      <td>913.898285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16796</th>\n",
       "      <td>100_20220831 20</td>\n",
       "      <td>808.115051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16797</th>\n",
       "      <td>100_20220831 21</td>\n",
       "      <td>742.103607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16798</th>\n",
       "      <td>100_20220831 22</td>\n",
       "      <td>661.415100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16799</th>\n",
       "      <td>100_20220831 23</td>\n",
       "      <td>553.260681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16800 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         num_date_time       answer\n",
       "0        1_20220825 00  1949.632446\n",
       "1        1_20220825 01  1886.484741\n",
       "2        1_20220825 02  1604.047119\n",
       "3        1_20220825 03  1502.918579\n",
       "4        1_20220825 04  1494.666382\n",
       "...                ...          ...\n",
       "16795  100_20220831 19   913.898285\n",
       "16796  100_20220831 20   808.115051\n",
       "16797  100_20220831 21   742.103607\n",
       "16798  100_20220831 22   661.415100\n",
       "16799  100_20220831 23   553.260681\n",
       "\n",
       "[16800 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('../../../../sample_submission.csv')\n",
    "\n",
    "# answer_34와 answer_5의 값을 새로운 컬럼에 할당\n",
    "submission['answer_34'] = preds_34\n",
    "submission['answer_5'] = preds_5\n",
    "\n",
    "# 'num_date_time'에서 년월일 부분만 추출\n",
    "submission['date'] = submission['num_date_time'].apply(lambda x: x.split('_')[1])\n",
    "submission['date'] = submission['date'].apply(lambda x: x.split(' ')[0])\n",
    "\n",
    "# 먼저 'answer' 컬럼을 'answer_34'와 'answer_5'의 평균으로 초기화\n",
    "submission['answer'] = (submission['answer_34'] + submission['answer_5']) / 2\n",
    "\n",
    "print(submission)\n",
    "# 'date'가 '20220826' 또는 '20220827'인 행의 'answer' 값을 해당 날짜의 'answer_34' 값으로 변경\n",
    "submission.loc[submission['date'].isin(['20220825', '20220826']), 'answer'] = submission.loc[submission['date'].isin(['20220825', '20220826']), 'answer_34']\n",
    "\n",
    "# 'date'가 '20220828'인 행의 'answer' 값을 해당 날짜의 'answer_5' 값으로 변경\n",
    "submission.loc[submission['date'] == '20220827', 'answer'] = submission.loc[submission['date'] == '20220827', 'answer_5']\n",
    "\n",
    "# 불필요한 컬럼 삭제\n",
    "submission = submission.drop(columns=['date', 'answer_34', 'answer_5'])\n",
    "\n",
    "submission.to_csv('submit_v27_xgb_953_seperate_real_edit2.csv', index=False)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_date_time</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_20220825 00</td>\n",
       "      <td>1959.369873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_20220825 01</td>\n",
       "      <td>1932.714905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_20220825 02</td>\n",
       "      <td>1676.093445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_20220825 03</td>\n",
       "      <td>1548.757446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_20220825 04</td>\n",
       "      <td>1560.819214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16795</th>\n",
       "      <td>100_20220831 19</td>\n",
       "      <td>899.233032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16796</th>\n",
       "      <td>100_20220831 20</td>\n",
       "      <td>808.955627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16797</th>\n",
       "      <td>100_20220831 21</td>\n",
       "      <td>757.248260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16798</th>\n",
       "      <td>100_20220831 22</td>\n",
       "      <td>656.413818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16799</th>\n",
       "      <td>100_20220831 23</td>\n",
       "      <td>556.596222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16800 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         num_date_time       answer\n",
       "0        1_20220825 00  1959.369873\n",
       "1        1_20220825 01  1932.714905\n",
       "2        1_20220825 02  1676.093445\n",
       "3        1_20220825 03  1548.757446\n",
       "4        1_20220825 04  1560.819214\n",
       "...                ...          ...\n",
       "16795  100_20220831 19   899.233032\n",
       "16796  100_20220831 20   808.955627\n",
       "16797  100_20220831 21   757.248260\n",
       "16798  100_20220831 22   656.413818\n",
       "16799  100_20220831 23   556.596222\n",
       "\n",
       "[16800 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('../../../../sample_submission.csv')\n",
    "submission['answer_34'] = preds_34\n",
    "submission['answer_5'] = preds_5\n",
    "# 'num_date_time'에서 년월일 부분만 추출\n",
    "submission['date'] = submission['num_date_time'].apply(lambda x: x.split(' ')[1])\n",
    "# 'date'가 '20220825' 또는 '20220827'인 행의 'power_5' 값을 0으로 변경\n",
    "submission.loc[submission['date'].isin(['20220825', '20220826']), 'power_5'] = submission.loc[submission['date'].isin(['20220825', '20220826']), 'answer_34']\n",
    "submission.loc[submission['date'].isin(['20220827']), 'answer_34'] = submission.loc[submission['date'].isin(['20220827']), 'power_5']\n",
    "submission['answer'] = (submission['answer_34'] + submission['answer_5']) / 2\n",
    "z = submission.copy()\n",
    "submission = pd.read_csv('../../../../sample_submission.csv')\n",
    "submission['answer'] = z['answer']\n",
    "#submission.to_csv('submit_v25_xgb_81_seperate.csv', index = False)\n",
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20230731_094643\\\"\n",
      "Presets specified: ['medium_quality']\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (204000 samples, 91.39 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230731_094643\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.16\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   82.17 GB / 511.09 GB (16.1%)\n",
      "Train Data Rows:    204000\n",
      "Train Data Columns: 50\n",
      "Label Column: power\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (25488.4, 0.0, 2451.03646, 2440.64886)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    19216.37 MB\n",
      "\tTrain Data (Original)  Memory Usage: 89.76 MB (0.5% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 17 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                      : 23 | ['temp', 'rainy', 'wind', 'hum', '연면적', ...]\n",
      "\t\t('int', [])                        : 26 | ['num', 'location', 'hour', 'day', 'month', ...]\n",
      "\t\t('object', ['datetime_as_object']) :  1 | ['date_time']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                : 23 | ['temp', 'rainy', 'wind', 'hum', '연면적', ...]\n",
      "\t\t('int', [])                  :  9 | ['num', 'location', 'hour', 'day', 'month', ...]\n",
      "\t\t('int', ['bool'])            : 17 | ['holiday', '건물기타', '공공', '대학교', '데이터센터', ...]\n",
      "\t\t('int', ['datetime_as_int']) :  2 | ['date_time', 'date_time.day']\n",
      "\t1.3s = Fit runtime\n",
      "\t50 features in original data used to generate 51 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 54.88 MB (0.3% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.43s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'SMAPE'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.012254901960784314, Train Rows: 201500, Val Rows: 2500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\tWarning: Exception caused KNeighborsUnif to fail during training... Skipping this model.\n",
      "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\knn\\knn_model.py\", line 97, in _fit\n",
      "    self.model = self._get_model_type()(**params).fit(X, y)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\sklearn\\neighbors\\_regression.py\", line 217, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 454, in _fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\sklearn\\base.py\", line 584, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1106, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
      "Fitting model: KNeighborsDist ...\n",
      "\tWarning: Exception caused KNeighborsDist to fail during training... Skipping this model.\n",
      "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\knn\\knn_model.py\", line 97, in _fit\n",
      "    self.model = self._get_model_type()(**params).fit(X, y)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\sklearn\\neighbors\\_regression.py\", line 217, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 454, in _fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\sklearn\\base.py\", line 584, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1106, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
      "Fitting model: LightGBMXT ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m train_data \u001b[39m=\u001b[39m TabularDataset(train)\n\u001b[0;32m      9\u001b[0m test_data \u001b[39m=\u001b[39m TabularDataset(test)\n\u001b[1;32m---> 10\u001b[0m predictor \u001b[39m=\u001b[39m TabularPredictor(label\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mpower\u001b[39;49m\u001b[39m'\u001b[39;49m,  eval_metric\u001b[39m=\u001b[39;49mmape_custom)\u001b[39m.\u001b[39;49mfit(train_data, presets\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmedium_quality\u001b[39;49m\u001b[39m'\u001b[39;49m,  ag_args_fit\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mnum_gpus\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m0\u001b[39;49m})\n\u001b[0;32m     12\u001b[0m y_pred \u001b[39m=\u001b[39m predictor\u001b[39m.\u001b[39mpredict(test_data)\n\u001b[0;32m     13\u001b[0m predictor\u001b[39m.\u001b[39mleaderboard() \u001b[39m#original FE\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\utils\\decorators.py:31\u001b[0m, in \u001b[0;36munpack.<locals>._unpack_inner.<locals>._call\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[0;32m     29\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     30\u001b[0m     gargs, gkwargs \u001b[39m=\u001b[39m g(\u001b[39m*\u001b[39mother_args, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m---> 31\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49mgargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mgkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\predictor\\predictor.py:986\u001b[0m, in \u001b[0;36mTabularPredictor.fit\u001b[1;34m(self, train_data, tuning_data, time_limit, presets, hyperparameters, feature_metadata, infer_limit, infer_limit_batch_size, fit_weighted_ensemble, calibrate_decision_threshold, num_cpus, num_gpus, **kwargs)\u001b[0m\n\u001b[0;32m    984\u001b[0m     aux_kwargs[\u001b[39m\"\u001b[39m\u001b[39mfit_weighted_ensemble\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    985\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave(silent\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)  \u001b[39m# Save predictor to disk to enable prediction and training after interrupt\u001b[39;00m\n\u001b[1;32m--> 986\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_learner\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m    987\u001b[0m     X\u001b[39m=\u001b[39;49mtrain_data,\n\u001b[0;32m    988\u001b[0m     X_val\u001b[39m=\u001b[39;49mtuning_data,\n\u001b[0;32m    989\u001b[0m     X_unlabeled\u001b[39m=\u001b[39;49munlabeled_data,\n\u001b[0;32m    990\u001b[0m     holdout_frac\u001b[39m=\u001b[39;49mholdout_frac,\n\u001b[0;32m    991\u001b[0m     num_bag_folds\u001b[39m=\u001b[39;49mnum_bag_folds,\n\u001b[0;32m    992\u001b[0m     num_bag_sets\u001b[39m=\u001b[39;49mnum_bag_sets,\n\u001b[0;32m    993\u001b[0m     num_stack_levels\u001b[39m=\u001b[39;49mnum_stack_levels,\n\u001b[0;32m    994\u001b[0m     hyperparameters\u001b[39m=\u001b[39;49mhyperparameters,\n\u001b[0;32m    995\u001b[0m     core_kwargs\u001b[39m=\u001b[39;49mcore_kwargs,\n\u001b[0;32m    996\u001b[0m     aux_kwargs\u001b[39m=\u001b[39;49maux_kwargs,\n\u001b[0;32m    997\u001b[0m     time_limit\u001b[39m=\u001b[39;49mtime_limit,\n\u001b[0;32m    998\u001b[0m     infer_limit\u001b[39m=\u001b[39;49minfer_limit,\n\u001b[0;32m    999\u001b[0m     infer_limit_batch_size\u001b[39m=\u001b[39;49minfer_limit_batch_size,\n\u001b[0;32m   1000\u001b[0m     verbosity\u001b[39m=\u001b[39;49mverbosity,\n\u001b[0;32m   1001\u001b[0m     use_bag_holdout\u001b[39m=\u001b[39;49muse_bag_holdout,\n\u001b[0;32m   1002\u001b[0m )\n\u001b[0;32m   1003\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_post_fit_vars()\n\u001b[0;32m   1005\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_post_fit(\n\u001b[0;32m   1006\u001b[0m     keep_only_best\u001b[39m=\u001b[39mkwargs[\u001b[39m\"\u001b[39m\u001b[39mkeep_only_best\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   1007\u001b[0m     refit_full\u001b[39m=\u001b[39mkwargs[\u001b[39m\"\u001b[39m\u001b[39mrefit_full\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     infer_limit\u001b[39m=\u001b[39minfer_limit,\n\u001b[0;32m   1013\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\learner\\abstract_learner.py:159\u001b[0m, in \u001b[0;36mAbstractTabularLearner.fit\u001b[1;34m(self, X, X_val, **kwargs)\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mLearner is already fit.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    158\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_fit_input(X\u001b[39m=\u001b[39mX, X_val\u001b[39m=\u001b[39mX_val, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 159\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X\u001b[39m=\u001b[39;49mX, X_val\u001b[39m=\u001b[39;49mX_val, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\learner\\default_learner.py:157\u001b[0m, in \u001b[0;36mDefaultLearner._fit\u001b[1;34m(self, X, X_val, X_unlabeled, holdout_frac, num_bag_folds, num_bag_sets, time_limit, infer_limit, infer_limit_batch_size, verbosity, **trainer_fit_kwargs)\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval_metric \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39meval_metric\n\u001b[0;32m    156\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave()\n\u001b[1;32m--> 157\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m    158\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    159\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    160\u001b[0m     X_val\u001b[39m=\u001b[39;49mX_val,\n\u001b[0;32m    161\u001b[0m     y_val\u001b[39m=\u001b[39;49my_val,\n\u001b[0;32m    162\u001b[0m     X_unlabeled\u001b[39m=\u001b[39;49mX_unlabeled,\n\u001b[0;32m    163\u001b[0m     holdout_frac\u001b[39m=\u001b[39;49mholdout_frac,\n\u001b[0;32m    164\u001b[0m     time_limit\u001b[39m=\u001b[39;49mtime_limit_trainer,\n\u001b[0;32m    165\u001b[0m     infer_limit\u001b[39m=\u001b[39;49minfer_limit,\n\u001b[0;32m    166\u001b[0m     infer_limit_batch_size\u001b[39m=\u001b[39;49minfer_limit_batch_size,\n\u001b[0;32m    167\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[0;32m    168\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtrainer_fit_kwargs,\n\u001b[0;32m    169\u001b[0m )\n\u001b[0;32m    170\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_trainer(trainer\u001b[39m=\u001b[39mtrainer)\n\u001b[0;32m    171\u001b[0m time_end \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\trainer\\auto_trainer.py:114\u001b[0m, in \u001b[0;36mAutoTrainer.fit\u001b[1;34m(self, X, y, hyperparameters, X_val, y_val, X_unlabeled, holdout_frac, num_stack_levels, core_kwargs, aux_kwargs, time_limit, infer_limit, infer_limit_batch_size, use_bag_holdout, groups, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m log_str \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m}\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    112\u001b[0m logger\u001b[39m.\u001b[39mlog(\u001b[39m20\u001b[39m, log_str)\n\u001b[1;32m--> 114\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_multi_and_ensemble(\n\u001b[0;32m    115\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    116\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    117\u001b[0m     X_val\u001b[39m=\u001b[39;49mX_val,\n\u001b[0;32m    118\u001b[0m     y_val\u001b[39m=\u001b[39;49my_val,\n\u001b[0;32m    119\u001b[0m     X_unlabeled\u001b[39m=\u001b[39;49mX_unlabeled,\n\u001b[0;32m    120\u001b[0m     hyperparameters\u001b[39m=\u001b[39;49mhyperparameters,\n\u001b[0;32m    121\u001b[0m     num_stack_levels\u001b[39m=\u001b[39;49mnum_stack_levels,\n\u001b[0;32m    122\u001b[0m     time_limit\u001b[39m=\u001b[39;49mtime_limit,\n\u001b[0;32m    123\u001b[0m     core_kwargs\u001b[39m=\u001b[39;49mcore_kwargs,\n\u001b[0;32m    124\u001b[0m     aux_kwargs\u001b[39m=\u001b[39;49maux_kwargs,\n\u001b[0;32m    125\u001b[0m     infer_limit\u001b[39m=\u001b[39;49minfer_limit,\n\u001b[0;32m    126\u001b[0m     infer_limit_batch_size\u001b[39m=\u001b[39;49minfer_limit_batch_size,\n\u001b[0;32m    127\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[0;32m    128\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:2371\u001b[0m, in \u001b[0;36mAbstractTrainer._train_multi_and_ensemble\u001b[1;34m(self, X, y, X_val, y_val, hyperparameters, X_unlabeled, num_stack_levels, time_limit, groups, **kwargs)\u001b[0m\n\u001b[0;32m   2369\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_rows_val \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(X_val)\n\u001b[0;32m   2370\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_cols_train \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mlist\u001b[39m(X\u001b[39m.\u001b[39mcolumns))\n\u001b[1;32m-> 2371\u001b[0m model_names_fit \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_multi_levels(\n\u001b[0;32m   2372\u001b[0m     X,\n\u001b[0;32m   2373\u001b[0m     y,\n\u001b[0;32m   2374\u001b[0m     hyperparameters\u001b[39m=\u001b[39;49mhyperparameters,\n\u001b[0;32m   2375\u001b[0m     X_val\u001b[39m=\u001b[39;49mX_val,\n\u001b[0;32m   2376\u001b[0m     y_val\u001b[39m=\u001b[39;49my_val,\n\u001b[0;32m   2377\u001b[0m     X_unlabeled\u001b[39m=\u001b[39;49mX_unlabeled,\n\u001b[0;32m   2378\u001b[0m     level_start\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m   2379\u001b[0m     level_end\u001b[39m=\u001b[39;49mnum_stack_levels \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m,\n\u001b[0;32m   2380\u001b[0m     time_limit\u001b[39m=\u001b[39;49mtime_limit,\n\u001b[0;32m   2381\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m   2382\u001b[0m )\n\u001b[0;32m   2383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_model_names()) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   2384\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAutoGluon did not successfully train any models\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:395\u001b[0m, in \u001b[0;36mAbstractTrainer.train_multi_levels\u001b[1;34m(self, X, y, hyperparameters, X_val, y_val, X_unlabeled, base_model_names, core_kwargs, aux_kwargs, level_start, level_end, time_limit, name_suffix, relative_stack, level_time_modifier, infer_limit, infer_limit_batch_size)\u001b[0m\n\u001b[0;32m    393\u001b[0m         core_kwargs_level[\u001b[39m\"\u001b[39m\u001b[39mtime_limit\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m core_kwargs_level\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtime_limit\u001b[39m\u001b[39m\"\u001b[39m, time_limit_core)\n\u001b[0;32m    394\u001b[0m         aux_kwargs_level[\u001b[39m\"\u001b[39m\u001b[39mtime_limit\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m aux_kwargs_level\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtime_limit\u001b[39m\u001b[39m\"\u001b[39m, time_limit_aux)\n\u001b[1;32m--> 395\u001b[0m     base_model_names, aux_models \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstack_new_level(\n\u001b[0;32m    396\u001b[0m         X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    397\u001b[0m         y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    398\u001b[0m         X_val\u001b[39m=\u001b[39;49mX_val,\n\u001b[0;32m    399\u001b[0m         y_val\u001b[39m=\u001b[39;49my_val,\n\u001b[0;32m    400\u001b[0m         X_unlabeled\u001b[39m=\u001b[39;49mX_unlabeled,\n\u001b[0;32m    401\u001b[0m         models\u001b[39m=\u001b[39;49mhyperparameters,\n\u001b[0;32m    402\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m    403\u001b[0m         base_model_names\u001b[39m=\u001b[39;49mbase_model_names,\n\u001b[0;32m    404\u001b[0m         core_kwargs\u001b[39m=\u001b[39;49mcore_kwargs_level,\n\u001b[0;32m    405\u001b[0m         aux_kwargs\u001b[39m=\u001b[39;49maux_kwargs_level,\n\u001b[0;32m    406\u001b[0m         name_suffix\u001b[39m=\u001b[39;49mname_suffix,\n\u001b[0;32m    407\u001b[0m         infer_limit\u001b[39m=\u001b[39;49minfer_limit,\n\u001b[0;32m    408\u001b[0m         infer_limit_batch_size\u001b[39m=\u001b[39;49minfer_limit_batch_size,\n\u001b[0;32m    409\u001b[0m     )\n\u001b[0;32m    410\u001b[0m     model_names_fit \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m base_model_names \u001b[39m+\u001b[39m aux_models\n\u001b[0;32m    411\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_best \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(model_names_fit) \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:539\u001b[0m, in \u001b[0;36mAbstractTrainer.stack_new_level\u001b[1;34m(self, X, y, models, X_val, y_val, X_unlabeled, level, base_model_names, core_kwargs, aux_kwargs, name_suffix, infer_limit, infer_limit_batch_size)\u001b[0m\n\u001b[0;32m    537\u001b[0m     core_kwargs[\u001b[39m\"\u001b[39m\u001b[39mname_suffix\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m core_kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mname_suffix\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m+\u001b[39m name_suffix\n\u001b[0;32m    538\u001b[0m     aux_kwargs[\u001b[39m\"\u001b[39m\u001b[39mname_suffix\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m aux_kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mname_suffix\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m+\u001b[39m name_suffix\n\u001b[1;32m--> 539\u001b[0m core_models \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstack_new_level_core(\n\u001b[0;32m    540\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    541\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    542\u001b[0m     X_val\u001b[39m=\u001b[39;49mX_val,\n\u001b[0;32m    543\u001b[0m     y_val\u001b[39m=\u001b[39;49my_val,\n\u001b[0;32m    544\u001b[0m     X_unlabeled\u001b[39m=\u001b[39;49mX_unlabeled,\n\u001b[0;32m    545\u001b[0m     models\u001b[39m=\u001b[39;49mmodels,\n\u001b[0;32m    546\u001b[0m     level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m    547\u001b[0m     infer_limit\u001b[39m=\u001b[39;49minfer_limit,\n\u001b[0;32m    548\u001b[0m     infer_limit_batch_size\u001b[39m=\u001b[39;49minfer_limit_batch_size,\n\u001b[0;32m    549\u001b[0m     base_model_names\u001b[39m=\u001b[39;49mbase_model_names,\n\u001b[0;32m    550\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcore_kwargs,\n\u001b[0;32m    551\u001b[0m )\n\u001b[0;32m    553\u001b[0m \u001b[39mif\u001b[39;00m X_val \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    554\u001b[0m     aux_models \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstack_new_level_aux(\n\u001b[0;32m    555\u001b[0m         X\u001b[39m=\u001b[39mX, y\u001b[39m=\u001b[39my, base_model_names\u001b[39m=\u001b[39mcore_models, level\u001b[39m=\u001b[39mlevel \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, infer_limit\u001b[39m=\u001b[39minfer_limit, infer_limit_batch_size\u001b[39m=\u001b[39minfer_limit_batch_size, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39maux_kwargs\n\u001b[0;32m    556\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:673\u001b[0m, in \u001b[0;36mAbstractTrainer.stack_new_level_core\u001b[1;34m(self, X, y, models, X_val, y_val, X_unlabeled, level, base_model_names, stack_name, ag_args, ag_args_fit, ag_args_ensemble, included_model_types, excluded_model_types, ensemble_type, name_suffix, get_models_func, refit_full, infer_limit, infer_limit_batch_size, **kwargs)\u001b[0m\n\u001b[0;32m    670\u001b[0m fit_kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(num_classes\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_classes)\n\u001b[0;32m    672\u001b[0m \u001b[39m# FIXME: TODO: v0.1 X_unlabeled isn't cached so it won't be available during refit_full or fit_extra.\u001b[39;00m\n\u001b[1;32m--> 673\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_multi(\n\u001b[0;32m    674\u001b[0m     X\u001b[39m=\u001b[39;49mX_init,\n\u001b[0;32m    675\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    676\u001b[0m     X_val\u001b[39m=\u001b[39;49mX_val,\n\u001b[0;32m    677\u001b[0m     y_val\u001b[39m=\u001b[39;49my_val,\n\u001b[0;32m    678\u001b[0m     X_unlabeled\u001b[39m=\u001b[39;49mX_unlabeled,\n\u001b[0;32m    679\u001b[0m     models\u001b[39m=\u001b[39;49mmodels,\n\u001b[0;32m    680\u001b[0m     level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m    681\u001b[0m     stack_name\u001b[39m=\u001b[39;49mstack_name,\n\u001b[0;32m    682\u001b[0m     compute_score\u001b[39m=\u001b[39;49mcompute_score,\n\u001b[0;32m    683\u001b[0m     fit_kwargs\u001b[39m=\u001b[39;49mfit_kwargs,\n\u001b[0;32m    684\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m    685\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:2321\u001b[0m, in \u001b[0;36mAbstractTrainer._train_multi\u001b[1;34m(self, X, y, models, hyperparameter_tune_kwargs, feature_prune_kwargs, k_fold, n_repeats, n_repeat_start, time_limit, **kwargs)\u001b[0m\n\u001b[0;32m   2319\u001b[0m \u001b[39mif\u001b[39;00m n_repeat_start \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   2320\u001b[0m     time_start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m-> 2321\u001b[0m     model_names_trained \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_multi_initial(\n\u001b[0;32m   2322\u001b[0m         X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m   2323\u001b[0m         y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m   2324\u001b[0m         models\u001b[39m=\u001b[39;49mmodels,\n\u001b[0;32m   2325\u001b[0m         k_fold\u001b[39m=\u001b[39;49mk_fold,\n\u001b[0;32m   2326\u001b[0m         n_repeats\u001b[39m=\u001b[39;49mn_repeats_initial,\n\u001b[0;32m   2327\u001b[0m         hyperparameter_tune_kwargs\u001b[39m=\u001b[39;49mhyperparameter_tune_kwargs,\n\u001b[0;32m   2328\u001b[0m         feature_prune_kwargs\u001b[39m=\u001b[39;49mfeature_prune_kwargs,\n\u001b[0;32m   2329\u001b[0m         time_limit\u001b[39m=\u001b[39;49mtime_limit,\n\u001b[0;32m   2330\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m   2331\u001b[0m     )\n\u001b[0;32m   2332\u001b[0m     n_repeat_start \u001b[39m=\u001b[39m n_repeats_initial\n\u001b[0;32m   2333\u001b[0m     \u001b[39mif\u001b[39;00m time_limit \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:2160\u001b[0m, in \u001b[0;36mAbstractTrainer._train_multi_initial\u001b[1;34m(self, X, y, models, k_fold, n_repeats, hyperparameter_tune_kwargs, time_limit, feature_prune_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m   2158\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m bagged:\n\u001b[0;32m   2159\u001b[0m     time_ratio \u001b[39m=\u001b[39m hpo_time_ratio \u001b[39mif\u001b[39;00m hpo_enabled \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m\n\u001b[1;32m-> 2160\u001b[0m     models \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_multi_fold(\n\u001b[0;32m   2161\u001b[0m         models\u001b[39m=\u001b[39;49mmodels,\n\u001b[0;32m   2162\u001b[0m         hyperparameter_tune_kwargs\u001b[39m=\u001b[39;49mhyperparameter_tune_kwargs,\n\u001b[0;32m   2163\u001b[0m         time_limit\u001b[39m=\u001b[39;49mtime_limit,\n\u001b[0;32m   2164\u001b[0m         time_split\u001b[39m=\u001b[39;49mtime_split,\n\u001b[0;32m   2165\u001b[0m         time_ratio\u001b[39m=\u001b[39;49mtime_ratio,\n\u001b[0;32m   2166\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_args,\n\u001b[0;32m   2167\u001b[0m     )\n\u001b[0;32m   2168\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2169\u001b[0m     time_ratio \u001b[39m=\u001b[39m hpo_time_ratio \u001b[39mif\u001b[39;00m hpo_enabled \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:2278\u001b[0m, in \u001b[0;36mAbstractTrainer._train_multi_fold\u001b[1;34m(self, X, y, models, time_limit, time_split, time_ratio, hyperparameter_tune_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m   2276\u001b[0m         time_start_model \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m   2277\u001b[0m         time_left \u001b[39m=\u001b[39m time_limit \u001b[39m-\u001b[39m (time_start_model \u001b[39m-\u001b[39m time_start)\n\u001b[1;32m-> 2278\u001b[0m model_name_trained_lst \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_single_full(\n\u001b[0;32m   2279\u001b[0m     X, y, model, time_limit\u001b[39m=\u001b[39;49mtime_left, hyperparameter_tune_kwargs\u001b[39m=\u001b[39;49mhyperparameter_tune_kwargs_model, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[0;32m   2280\u001b[0m )\n\u001b[0;32m   2282\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlow_memory:\n\u001b[0;32m   2283\u001b[0m     \u001b[39mdel\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:2051\u001b[0m, in \u001b[0;36mAbstractTrainer._train_single_full\u001b[1;34m(self, X, y, model, X_unlabeled, X_val, y_val, X_pseudo, y_pseudo, feature_prune, hyperparameter_tune_kwargs, stack_name, k_fold, k_fold_start, k_fold_end, n_repeats, n_repeat_start, level, time_limit, fit_kwargs, compute_score, total_resources, **kwargs)\u001b[0m\n\u001b[0;32m   2047\u001b[0m         bagged_model_fit_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_bagged_model_fit_kwargs(\n\u001b[0;32m   2048\u001b[0m             k_fold\u001b[39m=\u001b[39mk_fold, k_fold_start\u001b[39m=\u001b[39mk_fold_start, k_fold_end\u001b[39m=\u001b[39mk_fold_end, n_repeats\u001b[39m=\u001b[39mn_repeats, n_repeat_start\u001b[39m=\u001b[39mn_repeat_start\n\u001b[0;32m   2049\u001b[0m         )\n\u001b[0;32m   2050\u001b[0m         model_fit_kwargs\u001b[39m.\u001b[39mupdate(bagged_model_fit_kwargs)\n\u001b[1;32m-> 2051\u001b[0m     model_names_trained \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_and_save(\n\u001b[0;32m   2052\u001b[0m         X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m   2053\u001b[0m         y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m   2054\u001b[0m         model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m   2055\u001b[0m         X_val\u001b[39m=\u001b[39;49mX_val,\n\u001b[0;32m   2056\u001b[0m         y_val\u001b[39m=\u001b[39;49my_val,\n\u001b[0;32m   2057\u001b[0m         X_unlabeled\u001b[39m=\u001b[39;49mX_unlabeled,\n\u001b[0;32m   2058\u001b[0m         stack_name\u001b[39m=\u001b[39;49mstack_name,\n\u001b[0;32m   2059\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m   2060\u001b[0m         compute_score\u001b[39m=\u001b[39;49mcompute_score,\n\u001b[0;32m   2061\u001b[0m         total_resources\u001b[39m=\u001b[39;49mtotal_resources,\n\u001b[0;32m   2062\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_fit_kwargs,\n\u001b[0;32m   2063\u001b[0m     )\n\u001b[0;32m   2064\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave()\n\u001b[0;32m   2065\u001b[0m \u001b[39mreturn\u001b[39;00m model_names_trained\n",
      "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:1733\u001b[0m, in \u001b[0;36mAbstractTrainer._train_and_save\u001b[1;34m(self, X, y, model, X_val, y_val, stack_name, level, compute_score, total_resources, **model_fit_kwargs)\u001b[0m\n\u001b[0;32m   1731\u001b[0m     model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_single(X_w_pseudo, y_w_pseudo, model, X_val, y_val, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_fit_kwargs)\n\u001b[0;32m   1732\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1733\u001b[0m     model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_single(X, y, model, X_val, y_val, total_resources\u001b[39m=\u001b[39;49mtotal_resources, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_fit_kwargs)\n\u001b[0;32m   1735\u001b[0m fit_end_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m   1736\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight_evaluation:\n",
      "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:1684\u001b[0m, in \u001b[0;36mAbstractTrainer._train_single\u001b[1;34m(self, X, y, model, X_val, y_val, total_resources, **model_fit_kwargs)\u001b[0m\n\u001b[0;32m   1679\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_train_single\u001b[39m(\u001b[39mself\u001b[39m, X, y, model: AbstractModel, X_val\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, y_val\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, total_resources\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_fit_kwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AbstractModel:\n\u001b[0;32m   1680\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1681\u001b[0m \u001b[39m    Trains model but does not add the trained model to this Trainer.\u001b[39;00m\n\u001b[0;32m   1682\u001b[0m \u001b[39m    Returns trained model object.\u001b[39;00m\n\u001b[0;32m   1683\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1684\u001b[0m     model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X\u001b[39m=\u001b[39;49mX, y\u001b[39m=\u001b[39;49my, X_val\u001b[39m=\u001b[39;49mX_val, y_val\u001b[39m=\u001b[39;49my_val, total_resources\u001b[39m=\u001b[39;49mtotal_resources, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_fit_kwargs)\n\u001b[0;32m   1685\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py:829\u001b[0m, in \u001b[0;36mAbstractModel.fit\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    827\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidate_fit_resources(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    828\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_fit_memory_usage(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 829\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    830\u001b[0m \u001b[39mif\u001b[39;00m out \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    831\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\lgb_model.py:194\u001b[0m, in \u001b[0;36mLGBModel._fit\u001b[1;34m(self, X, y, X_val, y_val, time_limit, num_gpus, num_cpus, sample_weight, sample_weight_val, verbosity, **kwargs)\u001b[0m\n\u001b[0;32m    192\u001b[0m warnings\u001b[39m.\u001b[39mfilterwarnings(\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m, message\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcategorical_column in param dict is overridden.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    193\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 194\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m train_lgb_model(early_stopping_callback_kwargs\u001b[39m=\u001b[39;49mearly_stopping_callback_kwargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtrain_params)\n\u001b[0;32m    195\u001b[0m \u001b[39mexcept\u001b[39;00m LightGBMError:\n\u001b[0;32m    196\u001b[0m     \u001b[39mif\u001b[39;00m train_params[\u001b[39m\"\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgpu\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\lgb_utils.py:124\u001b[0m, in \u001b[0;36mtrain_lgb_model\u001b[1;34m(early_stopping_callback_kwargs, **train_params)\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[39mreturn\u001b[39;00m booster\u001b[39m.\u001b[39mfit(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrain_params)\n\u001b[0;32m    123\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 124\u001b[0m     \u001b[39mreturn\u001b[39;00m lgb\u001b[39m.\u001b[39;49mtrain(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtrain_params)\n",
      "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\lightgbm\\engine.py:292\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mfor\u001b[39;00m cb \u001b[39min\u001b[39;00m callbacks_before_iter:\n\u001b[0;32m    285\u001b[0m     cb(callback\u001b[39m.\u001b[39mCallbackEnv(model\u001b[39m=\u001b[39mbooster,\n\u001b[0;32m    286\u001b[0m                             params\u001b[39m=\u001b[39mparams,\n\u001b[0;32m    287\u001b[0m                             iteration\u001b[39m=\u001b[39mi,\n\u001b[0;32m    288\u001b[0m                             begin_iteration\u001b[39m=\u001b[39minit_iteration,\n\u001b[0;32m    289\u001b[0m                             end_iteration\u001b[39m=\u001b[39minit_iteration \u001b[39m+\u001b[39m num_boost_round,\n\u001b[0;32m    290\u001b[0m                             evaluation_result_list\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m))\n\u001b[1;32m--> 292\u001b[0m booster\u001b[39m.\u001b[39;49mupdate(fobj\u001b[39m=\u001b[39;49mfobj)\n\u001b[0;32m    294\u001b[0m evaluation_result_list \u001b[39m=\u001b[39m []\n\u001b[0;32m    295\u001b[0m \u001b[39m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\lightgbm\\basic.py:3021\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   3019\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__set_objective_to_none:\n\u001b[0;32m   3020\u001b[0m     \u001b[39mraise\u001b[39;00m LightGBMError(\u001b[39m'\u001b[39m\u001b[39mCannot update due to null objective function.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m-> 3021\u001b[0m _safe_call(_LIB\u001b[39m.\u001b[39;49mLGBM_BoosterUpdateOneIter(\n\u001b[0;32m   3022\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[0;32m   3023\u001b[0m     ctypes\u001b[39m.\u001b[39;49mbyref(is_finished)))\n\u001b[0;32m   3024\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__is_predicted_cur_iter \u001b[39m=\u001b[39m [\u001b[39mFalse\u001b[39;00m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__num_dataset)]\n\u001b[0;32m   3025\u001b[0m \u001b[39mreturn\u001b[39;00m is_finished\u001b[39m.\u001b[39mvalue \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from autogluon.core.metrics import make_scorer\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "mape_custom = make_scorer(name='SMAPE',\n",
    "                                 score_func=SMAPE,\n",
    "                                 optimum=0,\n",
    "                                 greater_is_better=False)\n",
    "train_data = TabularDataset(train)\n",
    "test_data = TabularDataset(test)\n",
    "predictor = TabularPredictor(label='power',  eval_metric=mape_custom).fit(train_data, presets='medium_quality',  ag_args_fit={'num_gpus': 0})\n",
    "\n",
    "y_pred = predictor.predict(test_data)\n",
    "predictor.leaderboard() #original FE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 44 features using 5000 rows with 5 shuffle sets...\n",
      "\t664.32s\t= Expected runtime (132.86s per shuffle set)\n",
      "\t495.12s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>num_day_hour_mean</th>\n",
       "      <td>65.736601</td>\n",
       "      <td>1.187328</td>\n",
       "      <td>1.276576e-08</td>\n",
       "      <td>5</td>\n",
       "      <td>68.181326</td>\n",
       "      <td>63.291876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <td>6.579000</td>\n",
       "      <td>0.303959</td>\n",
       "      <td>5.452113e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>7.204855</td>\n",
       "      <td>5.953144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_day_hour_std</th>\n",
       "      <td>5.889451</td>\n",
       "      <td>0.270891</td>\n",
       "      <td>5.355949e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>6.447219</td>\n",
       "      <td>5.331682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>연면적</th>\n",
       "      <td>2.414510</td>\n",
       "      <td>0.172040</td>\n",
       "      <td>3.072161e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>2.768742</td>\n",
       "      <td>2.060278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num</th>\n",
       "      <td>1.949075</td>\n",
       "      <td>0.162155</td>\n",
       "      <td>5.696279e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>2.282954</td>\n",
       "      <td>1.615195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>데이터센터</th>\n",
       "      <td>1.596359</td>\n",
       "      <td>0.107343</td>\n",
       "      <td>2.438577e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>1.817379</td>\n",
       "      <td>1.375338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>냉방면적</th>\n",
       "      <td>1.528947</td>\n",
       "      <td>0.118810</td>\n",
       "      <td>4.340412e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>1.773578</td>\n",
       "      <td>1.284316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CDH</th>\n",
       "      <td>1.522276</td>\n",
       "      <td>0.125423</td>\n",
       "      <td>5.480242e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>1.780524</td>\n",
       "      <td>1.264028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp</th>\n",
       "      <td>1.383953</td>\n",
       "      <td>0.154175</td>\n",
       "      <td>1.818010e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>1.701400</td>\n",
       "      <td>1.066505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>power_diff_ratio</th>\n",
       "      <td>1.176135</td>\n",
       "      <td>0.106621</td>\n",
       "      <td>8.016402e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>1.395669</td>\n",
       "      <td>0.956601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <td>0.946951</td>\n",
       "      <td>0.082031</td>\n",
       "      <td>6.690470e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>1.115854</td>\n",
       "      <td>0.778047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tem_x_hum</th>\n",
       "      <td>0.871180</td>\n",
       "      <td>0.096059</td>\n",
       "      <td>1.745371e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>1.068966</td>\n",
       "      <td>0.673394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rainy</th>\n",
       "      <td>0.841286</td>\n",
       "      <td>0.108820</td>\n",
       "      <td>3.285539e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>1.065347</td>\n",
       "      <td>0.617225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>THI</th>\n",
       "      <td>0.826594</td>\n",
       "      <td>0.099341</td>\n",
       "      <td>2.455901e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>1.031139</td>\n",
       "      <td>0.622049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>아파트</th>\n",
       "      <td>0.776835</td>\n",
       "      <td>0.023160</td>\n",
       "      <td>9.469148e-08</td>\n",
       "      <td>5</td>\n",
       "      <td>0.824522</td>\n",
       "      <td>0.729148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>power_increase_summer</th>\n",
       "      <td>0.671338</td>\n",
       "      <td>0.087467</td>\n",
       "      <td>3.380818e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.851434</td>\n",
       "      <td>0.491243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week</th>\n",
       "      <td>0.631369</td>\n",
       "      <td>0.056856</td>\n",
       "      <td>7.806855e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.748436</td>\n",
       "      <td>0.514301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>commute_period</th>\n",
       "      <td>0.571293</td>\n",
       "      <td>0.048597</td>\n",
       "      <td>6.223215e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.671356</td>\n",
       "      <td>0.471231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hour</th>\n",
       "      <td>0.541298</td>\n",
       "      <td>0.058737</td>\n",
       "      <td>1.637882e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.662237</td>\n",
       "      <td>0.420359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>태양광용량</th>\n",
       "      <td>0.513406</td>\n",
       "      <td>0.069509</td>\n",
       "      <td>3.935092e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.656526</td>\n",
       "      <td>0.370287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>0.426411</td>\n",
       "      <td>0.038609</td>\n",
       "      <td>7.977668e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.505906</td>\n",
       "      <td>0.346915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wind</th>\n",
       "      <td>0.420859</td>\n",
       "      <td>0.070298</td>\n",
       "      <td>9.003514e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.565603</td>\n",
       "      <td>0.276115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cos_time</th>\n",
       "      <td>0.414519</td>\n",
       "      <td>0.040885</td>\n",
       "      <td>1.121066e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.498700</td>\n",
       "      <td>0.330337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sin_time</th>\n",
       "      <td>0.409065</td>\n",
       "      <td>0.062226</td>\n",
       "      <td>6.231833e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.537190</td>\n",
       "      <td>0.280941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>상용</th>\n",
       "      <td>0.405791</td>\n",
       "      <td>0.046823</td>\n",
       "      <td>2.089935e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.502200</td>\n",
       "      <td>0.309382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hum</th>\n",
       "      <td>0.402163</td>\n",
       "      <td>0.054321</td>\n",
       "      <td>3.899024e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.514011</td>\n",
       "      <td>0.290315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cos_day</th>\n",
       "      <td>0.297029</td>\n",
       "      <td>0.046007</td>\n",
       "      <td>6.691173e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.391757</td>\n",
       "      <td>0.202301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>백화점및아울렛</th>\n",
       "      <td>0.244094</td>\n",
       "      <td>0.026834</td>\n",
       "      <td>1.724704e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.299345</td>\n",
       "      <td>0.188843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sin_day</th>\n",
       "      <td>0.197258</td>\n",
       "      <td>0.024787</td>\n",
       "      <td>2.929801e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.248294</td>\n",
       "      <td>0.146221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>연구소</th>\n",
       "      <td>0.196656</td>\n",
       "      <td>0.029287</td>\n",
       "      <td>5.732265e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.256959</td>\n",
       "      <td>0.136354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>병원</th>\n",
       "      <td>0.180365</td>\n",
       "      <td>0.017037</td>\n",
       "      <td>9.440299e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.215444</td>\n",
       "      <td>0.145286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>할인마트</th>\n",
       "      <td>0.174858</td>\n",
       "      <td>0.024428</td>\n",
       "      <td>4.454511e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.225156</td>\n",
       "      <td>0.124559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>대학교</th>\n",
       "      <td>0.173683</td>\n",
       "      <td>0.034208</td>\n",
       "      <td>1.716082e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.244118</td>\n",
       "      <td>0.103248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESS저장용량</th>\n",
       "      <td>0.171403</td>\n",
       "      <td>0.026563</td>\n",
       "      <td>6.705476e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.226096</td>\n",
       "      <td>0.116710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low_power_day</th>\n",
       "      <td>0.135492</td>\n",
       "      <td>0.013772</td>\n",
       "      <td>1.263542e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.163849</td>\n",
       "      <td>0.107134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <td>0.084833</td>\n",
       "      <td>0.014511</td>\n",
       "      <td>9.884956e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.114712</td>\n",
       "      <td>0.054954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>지식산업센터</th>\n",
       "      <td>0.050443</td>\n",
       "      <td>0.008077</td>\n",
       "      <td>7.624731e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.067074</td>\n",
       "      <td>0.033813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>공공</th>\n",
       "      <td>0.026282</td>\n",
       "      <td>0.007498</td>\n",
       "      <td>7.156852e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.041721</td>\n",
       "      <td>0.010842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>건물기타</th>\n",
       "      <td>0.021160</td>\n",
       "      <td>0.003859</td>\n",
       "      <td>1.270727e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.029107</td>\n",
       "      <td>0.013214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCS용량</th>\n",
       "      <td>0.018805</td>\n",
       "      <td>0.003694</td>\n",
       "      <td>1.698647e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.026411</td>\n",
       "      <td>0.011199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>호텔및리조트</th>\n",
       "      <td>0.014150</td>\n",
       "      <td>0.003013</td>\n",
       "      <td>2.323406e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.020353</td>\n",
       "      <td>0.007947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>body_temp</th>\n",
       "      <td>0.012385</td>\n",
       "      <td>0.001958</td>\n",
       "      <td>7.248722e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.016416</td>\n",
       "      <td>0.008354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>THI_group</th>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>3.006147e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000896</td>\n",
       "      <td>0.000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>holiday</th>\n",
       "      <td>0.000330</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>2.844456e-02</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000904</td>\n",
       "      <td>-0.000243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       importance    stddev       p_value  n   p99_high  \\\n",
       "num_day_hour_mean       65.736601  1.187328  1.276576e-08  5  68.181326   \n",
       "date_time                6.579000  0.303959  5.452113e-07  5   7.204855   \n",
       "num_day_hour_std         5.889451  0.270891  5.355949e-07  5   6.447219   \n",
       "연면적                      2.414510  0.172040  3.072161e-06  5   2.768742   \n",
       "num                      1.949075  0.162155  5.696279e-06  5   2.282954   \n",
       "데이터센터                    1.596359  0.107343  2.438577e-06  5   1.817379   \n",
       "냉방면적                     1.528947  0.118810  4.340412e-06  5   1.773578   \n",
       "CDH                      1.522276  0.125423  5.480242e-06  5   1.780524   \n",
       "temp                     1.383953  0.154175  1.818010e-05  5   1.701400   \n",
       "power_diff_ratio         1.176135  0.106621  8.016402e-06  5   1.395669   \n",
       "location                 0.946951  0.082031  6.690470e-06  5   1.115854   \n",
       "tem_x_hum                0.871180  0.096059  1.745371e-05  5   1.068966   \n",
       "rainy                    0.841286  0.108820  3.285539e-05  5   1.065347   \n",
       "THI                      0.826594  0.099341  2.455901e-05  5   1.031139   \n",
       "아파트                      0.776835  0.023160  9.469148e-08  5   0.824522   \n",
       "power_increase_summer    0.671338  0.087467  3.380818e-05  5   0.851434   \n",
       "week                     0.631369  0.056856  7.806855e-06  5   0.748436   \n",
       "commute_period           0.571293  0.048597  6.223215e-06  5   0.671356   \n",
       "hour                     0.541298  0.058737  1.637882e-05  5   0.662237   \n",
       "태양광용량                    0.513406  0.069509  3.935092e-05  5   0.656526   \n",
       "day                      0.426411  0.038609  7.977668e-06  5   0.505906   \n",
       "wind                     0.420859  0.070298  9.003514e-05  5   0.565603   \n",
       "cos_time                 0.414519  0.040885  1.121066e-05  5   0.498700   \n",
       "sin_time                 0.409065  0.062226  6.231833e-05  5   0.537190   \n",
       "상용                       0.405791  0.046823  2.089935e-05  5   0.502200   \n",
       "hum                      0.402163  0.054321  3.899024e-05  5   0.514011   \n",
       "cos_day                  0.297029  0.046007  6.691173e-05  5   0.391757   \n",
       "백화점및아울렛                  0.244094  0.026834  1.724704e-05  5   0.299345   \n",
       "sin_day                  0.197258  0.024787  2.929801e-05  5   0.248294   \n",
       "연구소                      0.196656  0.029287  5.732265e-05  5   0.256959   \n",
       "병원                       0.180365  0.017037  9.440299e-06  5   0.215444   \n",
       "할인마트                     0.174858  0.024428  4.454511e-05  5   0.225156   \n",
       "대학교                      0.173683  0.034208  1.716082e-04  5   0.244118   \n",
       "ESS저장용량                  0.171403  0.026563  6.705476e-05  5   0.226096   \n",
       "low_power_day            0.135492  0.013772  1.263542e-05  5   0.163849   \n",
       "month                    0.084833  0.014511  9.884956e-05  5   0.114712   \n",
       "지식산업센터                   0.050443  0.008077  7.624731e-05  5   0.067074   \n",
       "공공                       0.026282  0.007498  7.156852e-04  5   0.041721   \n",
       "건물기타                     0.021160  0.003859  1.270727e-04  5   0.029107   \n",
       "PCS용량                    0.018805  0.003694  1.698647e-04  5   0.026411   \n",
       "호텔및리조트                   0.014150  0.003013  2.323406e-04  5   0.020353   \n",
       "body_temp                0.012385  0.001958  7.248722e-05  5   0.016416   \n",
       "THI_group                0.000480  0.000202  3.006147e-03  5   0.000896   \n",
       "holiday                  0.000330  0.000279  2.844456e-02  5   0.000904   \n",
       "\n",
       "                         p99_low  \n",
       "num_day_hour_mean      63.291876  \n",
       "date_time               5.953144  \n",
       "num_day_hour_std        5.331682  \n",
       "연면적                     2.060278  \n",
       "num                     1.615195  \n",
       "데이터센터                   1.375338  \n",
       "냉방면적                    1.284316  \n",
       "CDH                     1.264028  \n",
       "temp                    1.066505  \n",
       "power_diff_ratio        0.956601  \n",
       "location                0.778047  \n",
       "tem_x_hum               0.673394  \n",
       "rainy                   0.617225  \n",
       "THI                     0.622049  \n",
       "아파트                     0.729148  \n",
       "power_increase_summer   0.491243  \n",
       "week                    0.514301  \n",
       "commute_period          0.471231  \n",
       "hour                    0.420359  \n",
       "태양광용량                   0.370287  \n",
       "day                     0.346915  \n",
       "wind                    0.276115  \n",
       "cos_time                0.330337  \n",
       "sin_time                0.280941  \n",
       "상용                      0.309382  \n",
       "hum                     0.290315  \n",
       "cos_day                 0.202301  \n",
       "백화점및아울렛                 0.188843  \n",
       "sin_day                 0.146221  \n",
       "연구소                     0.136354  \n",
       "병원                      0.145286  \n",
       "할인마트                    0.124559  \n",
       "대학교                     0.103248  \n",
       "ESS저장용량                 0.116710  \n",
       "low_power_day           0.107134  \n",
       "month                   0.054954  \n",
       "지식산업센터                  0.033813  \n",
       "공공                      0.010842  \n",
       "건물기타                    0.013214  \n",
       "PCS용량                   0.011199  \n",
       "호텔및리조트                  0.007947  \n",
       "body_temp               0.008354  \n",
       "THI_group               0.000064  \n",
       "holiday                -0.000243  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.feature_importance(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AG New_FE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20230803_093913\\\"\n",
      "Presets specified: ['medium_quality']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (204000 samples, 83.23 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230803_093913\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.16\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   75.73 GB / 511.09 GB (14.8%)\n",
      "Train Data Rows:    204000\n",
      "Train Data Columns: 45\n",
      "Label Column: power\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (25488.4, 0.0, 2451.03646, 2440.64886)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    15076.08 MB\n",
      "\tTrain Data (Original)  Memory Usage: 81.6 MB (0.5% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 8 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                      : 25 | ['temp', 'rainy', 'wind', 'hum', '연면적', ...]\n",
      "\t\t('int', [])                        : 19 | ['num', 'location', 'hour', 'day', 'month', ...]\n",
      "\t\t('object', ['datetime_as_object']) :  1 | ['date_time']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                : 24 | ['temp', 'rainy', 'wind', 'hum', '연면적', ...]\n",
      "\t\t('int', [])                  : 12 | ['num', 'location', 'hour', 'day', 'month', ...]\n",
      "\t\t('int', ['bool'])            :  8 | ['holiday', 'commute_period', 'power_increase_summer', 'increase_all', 'decrease_all', ...]\n",
      "\t\t('int', ['datetime_as_int']) :  2 | ['date_time', 'date_time.day']\n",
      "\t1.2s = Fit runtime\n",
      "\t45 features in original data used to generate 46 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 59.57 MB (0.4% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.36s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'SMAPE'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.012254901960784314, Train Rows: 201500, Val Rows: 2500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Excluded models: [] (Specified by `excluded_model_types`)\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\tWarning: Exception caused KNeighborsUnif to fail during training... Skipping this model.\n",
      "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\knn\\knn_model.py\", line 97, in _fit\n",
      "    self.model = self._get_model_type()(**params).fit(X, y)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\sklearn\\neighbors\\_regression.py\", line 217, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 454, in _fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\sklearn\\base.py\", line 584, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1106, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
      "Fitting model: KNeighborsDist ...\n",
      "\tWarning: Exception caused KNeighborsDist to fail during training... Skipping this model.\n",
      "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\knn\\knn_model.py\", line 97, in _fit\n",
      "    self.model = self._get_model_type()(**params).fit(X, y)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\sklearn\\neighbors\\_regression.py\", line 217, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 454, in _fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\sklearn\\base.py\", line 584, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1106, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
      "Fitting model: LightGBMXT ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 22163.4\tvalid_set's SMAPE: -5.04824\n",
      "[2000]\tvalid_set's l2: 17544\tvalid_set's SMAPE: -4.50106\n",
      "[3000]\tvalid_set's l2: 15396.6\tvalid_set's SMAPE: -4.18558\n",
      "[4000]\tvalid_set's l2: 14102.8\tvalid_set's SMAPE: -3.9867\n",
      "[5000]\tvalid_set's l2: 13221.4\tvalid_set's SMAPE: -3.83654\n",
      "[6000]\tvalid_set's l2: 12584.7\tvalid_set's SMAPE: -3.73558\n",
      "[7000]\tvalid_set's l2: 12054.7\tvalid_set's SMAPE: -3.64422\n",
      "[8000]\tvalid_set's l2: 11631.3\tvalid_set's SMAPE: -3.57147\n",
      "[9000]\tvalid_set's l2: 11295.4\tvalid_set's SMAPE: -3.51519\n",
      "[10000]\tvalid_set's l2: 11033.6\tvalid_set's SMAPE: -3.46164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-3.461\t = Validation score   (-SMAPE)\n",
      "\t62.08s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 18355.4\tvalid_set's SMAPE: -4.43201\n",
      "[2000]\tvalid_set's l2: 14394.5\tvalid_set's SMAPE: -3.99733\n",
      "[3000]\tvalid_set's l2: 12632.8\tvalid_set's SMAPE: -3.74818\n",
      "[4000]\tvalid_set's l2: 11838.8\tvalid_set's SMAPE: -3.59369\n",
      "[5000]\tvalid_set's l2: 11302.2\tvalid_set's SMAPE: -3.48237\n",
      "[6000]\tvalid_set's l2: 10817.3\tvalid_set's SMAPE: -3.38881\n",
      "[7000]\tvalid_set's l2: 10443.5\tvalid_set's SMAPE: -3.30824\n",
      "[8000]\tvalid_set's l2: 10150.6\tvalid_set's SMAPE: -3.243\n",
      "[9000]\tvalid_set's l2: 9907.3\tvalid_set's SMAPE: -3.19868\n",
      "[10000]\tvalid_set's l2: 9679.66\tvalid_set's SMAPE: -3.16302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-3.1616\t = Validation score   (-SMAPE)\n",
      "\t58.33s\t = Training   runtime\n",
      "\t0.52s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\tWarning: Exception caused RandomForestMSE to fail during training... Skipping this model.\n",
      "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\rf\\rf_model.py\", line 195, in _fit\n",
      "    model = model.fit(X, y, sample_weight=sample_weight)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 345, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\sklearn\\base.py\", line 584, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1106, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
      "Fitting model: CatBoost ...\n",
      "\t-3.6926\t = Validation score   (-SMAPE)\n",
      "\t272.27s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\tWarning: Exception caused ExtraTreesMSE to fail during training... Skipping this model.\n",
      "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\rf\\rf_model.py\", line 195, in _fit\n",
      "    model = model.fit(X, y, sample_weight=sample_weight)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 345, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\sklearn\\base.py\", line 584, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1106, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:170: RuntimeWarning: invalid value encountered in subtract\n",
      "  (X[self.cont_columns].values - cont_mean) / cont_std,\n",
      "c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:170: RuntimeWarning: invalid value encountered in subtract\n",
      "  (X[self.cont_columns].values - cont_mean) / cont_std,\n",
      "Metric SMAPE is not supported by this model - using mean_squared_error instead\n",
      "No improvement since epoch -1: early stopping\n",
      "\tWarning: Exception caused NeuralNetFastAI to fail during training... Skipping this model.\n",
      "\t\t[Errno 2] No such file or directory: 'C:\\\\Users\\\\ineeji\\\\AppData\\\\Local\\\\Temp\\\\tmpt_w7ruvt\\\\models\\\\model.pth'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py\", line 327, in _fit\n",
      "    self.model.fit_one_cycle(epochs, params[\"lr\"], cbs=callbacks)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\fastai\\callback\\schedule.py\", line 119, in fit_one_cycle\n",
      "    self.fit(n_epoch, cbs=ParamScheduler(scheds)+L(cbs), reset_opt=reset_opt, wd=wd, start_epoch=start_epoch)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\fastai\\learner.py\", line 264, in fit\n",
      "    self._with_events(self._do_fit, 'fit', CancelFitException, self._end_cleanup)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\fastai\\learner.py\", line 201, in _with_events\n",
      "    self(f'after_{event_type}');  final()\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\fastai\\learner.py\", line 172, in __call__\n",
      "    def __call__(self, event_name): L(event_name).map(self._call_one)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\fastcore\\foundation.py\", line 156, in map\n",
      "    def map(self, f, *args, **kwargs): return self._new(map_ex(self, f, *args, gen=False, **kwargs))\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\fastcore\\basics.py\", line 840, in map_ex\n",
      "    return list(res)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\fastcore\\basics.py\", line 825, in __call__\n",
      "    return self.func(*fargs, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\fastai\\learner.py\", line 176, in _call_one\n",
      "    for cb in self.cbs.sorted('order'): cb(event_name)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\fastai\\callback\\core.py\", line 62, in __call__\n",
      "    except Exception as e: raise modify_exception(e, f'Exception occured in `{self.__class__.__name__}` when calling event `{event_name}`:\\n\\t{e.args[0]}', replace=True)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\fastai\\callback\\core.py\", line 60, in __call__\n",
      "    try: res = getcallable(self, event_name)()\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\callbacks.py\", line 107, in after_fit\n",
      "    self.learn.load(f\"{self.fname}\", with_opt=self.with_opt)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\fastai\\learner.py\", line 420, in load\n",
      "    load_model(file, self.model, self.opt, device=device, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\fastai\\learner.py\", line 51, in load_model\n",
      "    state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\torch\\serialization.py\", line 594, in load\n",
      "    with _open_file_like(f, 'rb') as opened_file:\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\torch\\serialization.py\", line 230, in _open_file_like\n",
      "    return _open_file(name_or_buffer, mode)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\torch\\serialization.py\", line 211, in __init__\n",
      "    super(_open_file, self).__init__(open(name, mode))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\ineeji\\\\AppData\\\\Local\\\\Temp\\\\tmpt_w7ruvt\\\\models\\\\model.pth'\n",
      "Fitting model: XGBoost ...\n",
      "\t-3.112\t = Validation score   (-SMAPE)\n",
      "\t116.19s\t = Training   runtime\n",
      "\t0.6s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\tWarning: Exception caused NeuralNetTorch to fail during training... Skipping this model.\n",
      "\t\tInput X contains infinity or a value too large for dtype('float64').\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 184, in _fit\n",
      "    train_dataset, val_dataset = self._generate_datasets(X=X, y=y, params=processor_kwargs, X_val=X_val, y_val=y_val)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 456, in _generate_datasets\n",
      "    train_dataset = self._process_train_data(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 529, in _process_train_data\n",
      "    df = self.processor.fit_transform(df)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 727, in fit_transform\n",
      "    result = self._fit_transform(X, y, _fit_transform_one)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 658, in _fit_transform\n",
      "    return Parallel(n_jobs=self.n_jobs)(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\joblib\\parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\joblib\\parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\joblib\\parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\sklearn\\pipeline.py\", line 437, in fit_transform\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\sklearn\\pipeline.py\", line 359, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\sklearn\\base.py\", line 878, in fit_transform\n",
      "    return self.fit(X, **fit_params).transform(X)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\sklearn\\impute\\_base.py\", line 390, in fit\n",
      "    X = self._validate_input(X, in_fit=True)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\sklearn\\impute\\_base.py\", line 344, in _validate_input\n",
      "    raise ve\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\sklearn\\impute\\_base.py\", line 327, in _validate_input\n",
      "    X = self._validate_data(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\sklearn\\base.py\", line 565, in _validate_data\n",
      "    X = check_array(X, input_name=\"X\", **check_params)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains infinity or a value too large for dtype('float64').\n",
      "Fitting model: LightGBMLarge ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 13363.4\tvalid_set's SMAPE: -3.84008\n",
      "[2000]\tvalid_set's l2: 10996.6\tvalid_set's SMAPE: -3.41487\n",
      "[3000]\tvalid_set's l2: 10155.2\tvalid_set's SMAPE: -3.21652\n",
      "[4000]\tvalid_set's l2: 9620.14\tvalid_set's SMAPE: -3.07579\n",
      "[5000]\tvalid_set's l2: 9356.09\tvalid_set's SMAPE: -2.98966\n",
      "[6000]\tvalid_set's l2: 9053.18\tvalid_set's SMAPE: -2.91974\n",
      "[7000]\tvalid_set's l2: 8891.55\tvalid_set's SMAPE: -2.86755\n",
      "[8000]\tvalid_set's l2: 8778.29\tvalid_set's SMAPE: -2.8289\n",
      "[9000]\tvalid_set's l2: 8709.66\tvalid_set's SMAPE: -2.79353\n",
      "[10000]\tvalid_set's l2: 8630.01\tvalid_set's SMAPE: -2.76402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-2.7636\t = Validation score   (-SMAPE)\n",
      "\t79.26s\t = Training   runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-2.7551\t = Validation score   (-SMAPE)\n",
      "\t0.26s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 678.45s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230803_093913\\\")\n"
     ]
    }
   ],
   "source": [
    "from autogluon.core.metrics import make_scorer\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "mape_custom = make_scorer(name='SMAPE',\n",
    "                                 score_func=SMAPE,\n",
    "                                 optimum=0,\n",
    "                                 greater_is_better=False)\n",
    "train_data = TabularDataset(train)\n",
    "test_data = TabularDataset(test)\n",
    "predictor = TabularPredictor(label='power',  eval_metric=mape_custom).fit(train_data, presets='medium_quality',  ag_args_fit={'num_gpus': 0},excluded_model_types = ['CatBoost'])\n",
    "\n",
    "y_pred = predictor.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 model  score_val  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  WeightedEnsemble_L2  -2.755108       1.156371  195.707713                0.001241           0.260834            2       True          6\n",
      "1        LightGBMLarge  -2.763562       0.551963   79.261877                0.551963          79.261877            1       True          5\n",
      "2              XGBoost  -3.111982       0.603167  116.185003                0.603167         116.185003            1       True          4\n",
      "3             LightGBM  -3.161621       0.517561   58.331221                0.517561          58.331221            1       True          2\n",
      "4           LightGBMXT  -3.460959       0.380095   62.081198                0.380095          62.081198            1       True          1\n",
      "5             CatBoost  -3.692553       0.009073  272.267638                0.009073         272.267638            1       True          3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-2.755108</td>\n",
       "      <td>1.156371</td>\n",
       "      <td>195.707713</td>\n",
       "      <td>0.001241</td>\n",
       "      <td>0.260834</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>-2.763562</td>\n",
       "      <td>0.551963</td>\n",
       "      <td>79.261877</td>\n",
       "      <td>0.551963</td>\n",
       "      <td>79.261877</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>-3.111982</td>\n",
       "      <td>0.603167</td>\n",
       "      <td>116.185003</td>\n",
       "      <td>0.603167</td>\n",
       "      <td>116.185003</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>-3.161621</td>\n",
       "      <td>0.517561</td>\n",
       "      <td>58.331221</td>\n",
       "      <td>0.517561</td>\n",
       "      <td>58.331221</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>-3.460959</td>\n",
       "      <td>0.380095</td>\n",
       "      <td>62.081198</td>\n",
       "      <td>0.380095</td>\n",
       "      <td>62.081198</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>-3.692553</td>\n",
       "      <td>0.009073</td>\n",
       "      <td>272.267638</td>\n",
       "      <td>0.009073</td>\n",
       "      <td>272.267638</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  score_val  pred_time_val    fit_time  \\\n",
       "0  WeightedEnsemble_L2  -2.755108       1.156371  195.707713   \n",
       "1        LightGBMLarge  -2.763562       0.551963   79.261877   \n",
       "2              XGBoost  -3.111982       0.603167  116.185003   \n",
       "3             LightGBM  -3.161621       0.517561   58.331221   \n",
       "4           LightGBMXT  -3.460959       0.380095   62.081198   \n",
       "5             CatBoost  -3.692553       0.009073  272.267638   \n",
       "\n",
       "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                0.001241           0.260834            2       True   \n",
       "1                0.551963          79.261877            1       True   \n",
       "2                0.603167         116.185003            1       True   \n",
       "3                0.517561          58.331221            1       True   \n",
       "4                0.380095          62.081198            1       True   \n",
       "5                0.009073         272.267638            1       True   \n",
       "\n",
       "   fit_order  \n",
       "0          6  \n",
       "1          5  \n",
       "2          4  \n",
       "3          2  \n",
       "4          1  \n",
       "5          3  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard() #폭염경보 + 이전시간 온도차 + 빌딩 라벨인코딩으로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 model  score_val  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  WeightedEnsemble_L2  -2.700228       1.301972  264.001806                0.000000           0.337093            2       True          6\n",
      "1        LightGBMLarge  -2.716487       0.598792  121.342618                0.598792         121.342618            1       True          5\n",
      "2              XGBoost  -3.064374       0.703180  142.322095                0.703180         142.322095            1       True          4\n",
      "3             LightGBM  -3.068908       0.396613   66.402752                0.396613          66.402752            1       True          2\n",
      "4           LightGBMXT  -3.326139       0.382917   58.443653                0.382917          58.443653            1       True          1\n",
      "5             CatBoost  -3.636162       0.013451  432.787150                0.013451         432.787150            1       True          3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-2.700228</td>\n",
       "      <td>1.301972</td>\n",
       "      <td>264.001806</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.337093</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>-2.716487</td>\n",
       "      <td>0.598792</td>\n",
       "      <td>121.342618</td>\n",
       "      <td>0.598792</td>\n",
       "      <td>121.342618</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>-3.064374</td>\n",
       "      <td>0.703180</td>\n",
       "      <td>142.322095</td>\n",
       "      <td>0.703180</td>\n",
       "      <td>142.322095</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>-3.068908</td>\n",
       "      <td>0.396613</td>\n",
       "      <td>66.402752</td>\n",
       "      <td>0.396613</td>\n",
       "      <td>66.402752</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>-3.326139</td>\n",
       "      <td>0.382917</td>\n",
       "      <td>58.443653</td>\n",
       "      <td>0.382917</td>\n",
       "      <td>58.443653</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>-3.636162</td>\n",
       "      <td>0.013451</td>\n",
       "      <td>432.787150</td>\n",
       "      <td>0.013451</td>\n",
       "      <td>432.787150</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  score_val  pred_time_val    fit_time  \\\n",
       "0  WeightedEnsemble_L2  -2.700228       1.301972  264.001806   \n",
       "1        LightGBMLarge  -2.716487       0.598792  121.342618   \n",
       "2              XGBoost  -3.064374       0.703180  142.322095   \n",
       "3             LightGBM  -3.068908       0.396613   66.402752   \n",
       "4           LightGBMXT  -3.326139       0.382917   58.443653   \n",
       "5             CatBoost  -3.636162       0.013451  432.787150   \n",
       "\n",
       "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                0.000000           0.337093            2       True   \n",
       "1                0.598792         121.342618            1       True   \n",
       "2                0.703180         142.322095            1       True   \n",
       "3                0.396613          66.402752            1       True   \n",
       "4                0.382917          58.443653            1       True   \n",
       "5                0.013451         432.787150            1       True   \n",
       "\n",
       "   fit_order  \n",
       "0          6  \n",
       "1          5  \n",
       "2          4  \n",
       "3          2  \n",
       "4          1  \n",
       "5          3  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard() #폭염경보 + 이전시간 온도차"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 model  score_val  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  WeightedEnsemble_L2  -2.681919       1.149982  178.041445                0.000995           0.391893            2       True          6\n",
      "1        LightGBMLarge  -2.702160       0.569348   82.720381                0.569348          82.720381            1       True          5\n",
      "2              XGBoost  -2.999358       0.579639   94.929172                0.579639          94.929172            1       True          4\n",
      "3             LightGBM  -3.091107       0.388938   64.011667                0.388938          64.011667            1       True          2\n",
      "4           LightGBMXT  -3.358897       0.449513   67.408445                0.449513          67.408445            1       True          1\n",
      "5             CatBoost  -3.614412       0.009530  209.346893                0.009530         209.346893            1       True          3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-2.681919</td>\n",
       "      <td>1.149982</td>\n",
       "      <td>178.041445</td>\n",
       "      <td>0.000995</td>\n",
       "      <td>0.391893</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>-2.702160</td>\n",
       "      <td>0.569348</td>\n",
       "      <td>82.720381</td>\n",
       "      <td>0.569348</td>\n",
       "      <td>82.720381</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>-2.999358</td>\n",
       "      <td>0.579639</td>\n",
       "      <td>94.929172</td>\n",
       "      <td>0.579639</td>\n",
       "      <td>94.929172</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>-3.091107</td>\n",
       "      <td>0.388938</td>\n",
       "      <td>64.011667</td>\n",
       "      <td>0.388938</td>\n",
       "      <td>64.011667</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>-3.358897</td>\n",
       "      <td>0.449513</td>\n",
       "      <td>67.408445</td>\n",
       "      <td>0.449513</td>\n",
       "      <td>67.408445</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>-3.614412</td>\n",
       "      <td>0.009530</td>\n",
       "      <td>209.346893</td>\n",
       "      <td>0.009530</td>\n",
       "      <td>209.346893</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  score_val  pred_time_val    fit_time  \\\n",
       "0  WeightedEnsemble_L2  -2.681919       1.149982  178.041445   \n",
       "1        LightGBMLarge  -2.702160       0.569348   82.720381   \n",
       "2              XGBoost  -2.999358       0.579639   94.929172   \n",
       "3             LightGBM  -3.091107       0.388938   64.011667   \n",
       "4           LightGBMXT  -3.358897       0.449513   67.408445   \n",
       "5             CatBoost  -3.614412       0.009530  209.346893   \n",
       "\n",
       "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                0.000995           0.391893            2       True   \n",
       "1                0.569348          82.720381            1       True   \n",
       "2                0.579639          94.929172            1       True   \n",
       "3                0.388938          64.011667            1       True   \n",
       "4                0.449513          67.408445            1       True   \n",
       "5                0.009530         209.346893            1       True   \n",
       "\n",
       "   fit_order  \n",
       "0          6  \n",
       "1          5  \n",
       "2          4  \n",
       "3          2  \n",
       "4          1  \n",
       "5          3  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard() #폭염경보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 model  score_val  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  WeightedEnsemble_L2  -2.705418       1.232151  200.417005                0.001001           0.364123            2       True          6\n",
      "1        LightGBMLarge  -2.713969       0.599902   90.960732                0.599902          90.960732            1       True          5\n",
      "2             LightGBM  -3.072975       0.404353   62.169089                0.404353          62.169089            1       True          2\n",
      "3              XGBoost  -3.087154       0.631249  109.092149                0.631249         109.092149            1       True          4\n",
      "4           LightGBMXT  -3.371737       0.607214   63.777059                0.607214          63.777059            1       True          1\n",
      "5             CatBoost  -3.653967       0.006984  240.367055                0.006984         240.367055            1       True          3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-2.705418</td>\n",
       "      <td>1.232151</td>\n",
       "      <td>200.417005</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.364123</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>-2.713969</td>\n",
       "      <td>0.599902</td>\n",
       "      <td>90.960732</td>\n",
       "      <td>0.599902</td>\n",
       "      <td>90.960732</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>-3.072975</td>\n",
       "      <td>0.404353</td>\n",
       "      <td>62.169089</td>\n",
       "      <td>0.404353</td>\n",
       "      <td>62.169089</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>-3.087154</td>\n",
       "      <td>0.631249</td>\n",
       "      <td>109.092149</td>\n",
       "      <td>0.631249</td>\n",
       "      <td>109.092149</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>-3.371737</td>\n",
       "      <td>0.607214</td>\n",
       "      <td>63.777059</td>\n",
       "      <td>0.607214</td>\n",
       "      <td>63.777059</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>-3.653967</td>\n",
       "      <td>0.006984</td>\n",
       "      <td>240.367055</td>\n",
       "      <td>0.006984</td>\n",
       "      <td>240.367055</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  score_val  pred_time_val    fit_time  \\\n",
       "0  WeightedEnsemble_L2  -2.705418       1.232151  200.417005   \n",
       "1        LightGBMLarge  -2.713969       0.599902   90.960732   \n",
       "2             LightGBM  -3.072975       0.404353   62.169089   \n",
       "3              XGBoost  -3.087154       0.631249  109.092149   \n",
       "4           LightGBMXT  -3.371737       0.607214   63.777059   \n",
       "5             CatBoost  -3.653967       0.006984  240.367055   \n",
       "\n",
       "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                0.001001           0.364123            2       True   \n",
       "1                0.599902          90.960732            1       True   \n",
       "2                0.404353          62.169089            1       True   \n",
       "3                0.631249         109.092149            1       True   \n",
       "4                0.607214          63.777059            1       True   \n",
       "5                0.006984         240.367055            1       True   \n",
       "\n",
       "   fit_order  \n",
       "0          6  \n",
       "1          5  \n",
       "2          2  \n",
       "3          4  \n",
       "4          1  \n",
       "5          3  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard() #fill na 내꺼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 45 features using 5000 rows with 5 shuffle sets...\n",
      "\t703.51s\t= Expected runtime (140.7s per shuffle set)\n",
      "\t528.65s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>num_day_hour_mean</th>\n",
       "      <td>69.230542</td>\n",
       "      <td>1.259845</td>\n",
       "      <td>1.315428e-08</td>\n",
       "      <td>5</td>\n",
       "      <td>71.824581</td>\n",
       "      <td>66.636504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <td>6.498305</td>\n",
       "      <td>0.263896</td>\n",
       "      <td>3.256558e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>7.041671</td>\n",
       "      <td>5.954939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_day_hour_std</th>\n",
       "      <td>5.498241</td>\n",
       "      <td>0.226371</td>\n",
       "      <td>3.440264e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>5.964343</td>\n",
       "      <td>5.032139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num</th>\n",
       "      <td>1.696980</td>\n",
       "      <td>0.176145</td>\n",
       "      <td>1.373215e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>2.059664</td>\n",
       "      <td>1.334296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>연면적</th>\n",
       "      <td>1.682921</td>\n",
       "      <td>0.135450</td>\n",
       "      <td>4.992308e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>1.961814</td>\n",
       "      <td>1.404027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CDH</th>\n",
       "      <td>1.513424</td>\n",
       "      <td>0.145057</td>\n",
       "      <td>1.000439e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>1.812098</td>\n",
       "      <td>1.214750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp</th>\n",
       "      <td>1.437582</td>\n",
       "      <td>0.163732</td>\n",
       "      <td>1.984788e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>1.774709</td>\n",
       "      <td>1.100455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>power_diff_ratio</th>\n",
       "      <td>1.090795</td>\n",
       "      <td>0.099098</td>\n",
       "      <td>8.085433e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>1.294839</td>\n",
       "      <td>0.886751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>태양광효율</th>\n",
       "      <td>0.987542</td>\n",
       "      <td>0.084378</td>\n",
       "      <td>6.333697e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>1.161277</td>\n",
       "      <td>0.813807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>냉방면적</th>\n",
       "      <td>0.964913</td>\n",
       "      <td>0.099952</td>\n",
       "      <td>1.362076e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>1.170715</td>\n",
       "      <td>0.759111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tem_x_hum</th>\n",
       "      <td>0.914948</td>\n",
       "      <td>0.100631</td>\n",
       "      <td>1.727998e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>1.122148</td>\n",
       "      <td>0.707749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>THI</th>\n",
       "      <td>0.802440</td>\n",
       "      <td>0.102808</td>\n",
       "      <td>3.163642e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>1.014122</td>\n",
       "      <td>0.590757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>연면_냉방면적</th>\n",
       "      <td>0.667330</td>\n",
       "      <td>0.088033</td>\n",
       "      <td>3.551270e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.848590</td>\n",
       "      <td>0.486069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <td>0.654423</td>\n",
       "      <td>0.072570</td>\n",
       "      <td>1.785234e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.803846</td>\n",
       "      <td>0.504999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week</th>\n",
       "      <td>0.621740</td>\n",
       "      <td>0.063021</td>\n",
       "      <td>1.249596e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.751501</td>\n",
       "      <td>0.491978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hour</th>\n",
       "      <td>0.433304</td>\n",
       "      <td>0.058011</td>\n",
       "      <td>3.764837e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.552750</td>\n",
       "      <td>0.313859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sin_time</th>\n",
       "      <td>0.427704</td>\n",
       "      <td>0.065563</td>\n",
       "      <td>6.423192e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.562698</td>\n",
       "      <td>0.292709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hum</th>\n",
       "      <td>0.390030</td>\n",
       "      <td>0.056593</td>\n",
       "      <td>5.173101e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.506557</td>\n",
       "      <td>0.273504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>0.380024</td>\n",
       "      <td>0.035889</td>\n",
       "      <td>9.432905e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.453920</td>\n",
       "      <td>0.306128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tropical_night</th>\n",
       "      <td>0.377707</td>\n",
       "      <td>0.042655</td>\n",
       "      <td>1.919122e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.465535</td>\n",
       "      <td>0.289879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp_wind</th>\n",
       "      <td>0.371436</td>\n",
       "      <td>0.061096</td>\n",
       "      <td>8.475863e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.497233</td>\n",
       "      <td>0.245639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rainy_category</th>\n",
       "      <td>0.307631</td>\n",
       "      <td>0.019169</td>\n",
       "      <td>1.799651e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.347100</td>\n",
       "      <td>0.268163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>power_increase_summer</th>\n",
       "      <td>0.301684</td>\n",
       "      <td>0.043049</td>\n",
       "      <td>4.843029e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.390322</td>\n",
       "      <td>0.213046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>태양광용량</th>\n",
       "      <td>0.300354</td>\n",
       "      <td>0.037768</td>\n",
       "      <td>2.938032e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.378119</td>\n",
       "      <td>0.222589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wind</th>\n",
       "      <td>0.295872</td>\n",
       "      <td>0.047103</td>\n",
       "      <td>7.454769e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.392858</td>\n",
       "      <td>0.198886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cos_day</th>\n",
       "      <td>0.285398</td>\n",
       "      <td>0.039949</td>\n",
       "      <td>4.488816e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.367653</td>\n",
       "      <td>0.203143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cos_time</th>\n",
       "      <td>0.268347</td>\n",
       "      <td>0.035649</td>\n",
       "      <td>3.651239e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.341749</td>\n",
       "      <td>0.194945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sin_day</th>\n",
       "      <td>0.211485</td>\n",
       "      <td>0.032100</td>\n",
       "      <td>6.178442e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.277580</td>\n",
       "      <td>0.145390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESS저장용량</th>\n",
       "      <td>0.175083</td>\n",
       "      <td>0.029336</td>\n",
       "      <td>9.114349e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.235486</td>\n",
       "      <td>0.114679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>증가_day_hour_sum</th>\n",
       "      <td>0.155738</td>\n",
       "      <td>0.028557</td>\n",
       "      <td>1.297895e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.214537</td>\n",
       "      <td>0.096938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>commute_period</th>\n",
       "      <td>0.115864</td>\n",
       "      <td>0.021297</td>\n",
       "      <td>1.310216e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.159714</td>\n",
       "      <td>0.072013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>감소_day_hour_sum</th>\n",
       "      <td>0.092107</td>\n",
       "      <td>0.022289</td>\n",
       "      <td>3.812249e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.138000</td>\n",
       "      <td>0.046214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rainy</th>\n",
       "      <td>0.082122</td>\n",
       "      <td>0.013327</td>\n",
       "      <td>8.037819e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.109562</td>\n",
       "      <td>0.054682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low_power_day</th>\n",
       "      <td>0.078621</td>\n",
       "      <td>0.009450</td>\n",
       "      <td>2.457282e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.098079</td>\n",
       "      <td>0.059163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heatwave_caution</th>\n",
       "      <td>0.076352</td>\n",
       "      <td>0.011474</td>\n",
       "      <td>5.938987e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.099976</td>\n",
       "      <td>0.052728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tem_x_hum_diff</th>\n",
       "      <td>0.059718</td>\n",
       "      <td>0.013064</td>\n",
       "      <td>2.581407e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.086617</td>\n",
       "      <td>0.032819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp_diff</th>\n",
       "      <td>0.053959</td>\n",
       "      <td>0.013498</td>\n",
       "      <td>4.330944e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.081751</td>\n",
       "      <td>0.026167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <td>0.045390</td>\n",
       "      <td>0.007981</td>\n",
       "      <td>1.101161e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.061823</td>\n",
       "      <td>0.028957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>body_temp</th>\n",
       "      <td>0.019421</td>\n",
       "      <td>0.003325</td>\n",
       "      <td>9.920998e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.026267</td>\n",
       "      <td>0.012574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCS용량</th>\n",
       "      <td>0.014723</td>\n",
       "      <td>0.002425</td>\n",
       "      <td>8.526906e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.019717</td>\n",
       "      <td>0.009729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heatwave_alert</th>\n",
       "      <td>0.012761</td>\n",
       "      <td>0.003801</td>\n",
       "      <td>8.420276e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.020587</td>\n",
       "      <td>0.004936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decrease_all</th>\n",
       "      <td>0.001783</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>6.823533e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002817</td>\n",
       "      <td>0.000749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>holiday</th>\n",
       "      <td>0.001070</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>1.284079e-02</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002491</td>\n",
       "      <td>-0.000351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>increase_all</th>\n",
       "      <td>0.000864</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>8.965876e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>-0.000163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>THI_group</th>\n",
       "      <td>0.000613</td>\n",
       "      <td>0.000378</td>\n",
       "      <td>1.115871e-02</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001391</td>\n",
       "      <td>-0.000166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       importance    stddev       p_value  n   p99_high  \\\n",
       "num_day_hour_mean       69.230542  1.259845  1.315428e-08  5  71.824581   \n",
       "date_time                6.498305  0.263896  3.256558e-07  5   7.041671   \n",
       "num_day_hour_std         5.498241  0.226371  3.440264e-07  5   5.964343   \n",
       "num                      1.696980  0.176145  1.373215e-05  5   2.059664   \n",
       "연면적                      1.682921  0.135450  4.992308e-06  5   1.961814   \n",
       "CDH                      1.513424  0.145057  1.000439e-05  5   1.812098   \n",
       "temp                     1.437582  0.163732  1.984788e-05  5   1.774709   \n",
       "power_diff_ratio         1.090795  0.099098  8.085433e-06  5   1.294839   \n",
       "태양광효율                    0.987542  0.084378  6.333697e-06  5   1.161277   \n",
       "냉방면적                     0.964913  0.099952  1.362076e-05  5   1.170715   \n",
       "tem_x_hum                0.914948  0.100631  1.727998e-05  5   1.122148   \n",
       "THI                      0.802440  0.102808  3.163642e-05  5   1.014122   \n",
       "연면_냉방면적                  0.667330  0.088033  3.551270e-05  5   0.848590   \n",
       "location                 0.654423  0.072570  1.785234e-05  5   0.803846   \n",
       "week                     0.621740  0.063021  1.249596e-05  5   0.751501   \n",
       "hour                     0.433304  0.058011  3.764837e-05  5   0.552750   \n",
       "sin_time                 0.427704  0.065563  6.423192e-05  5   0.562698   \n",
       "hum                      0.390030  0.056593  5.173101e-05  5   0.506557   \n",
       "day                      0.380024  0.035889  9.432905e-06  5   0.453920   \n",
       "tropical_night           0.377707  0.042655  1.919122e-05  5   0.465535   \n",
       "temp_wind                0.371436  0.061096  8.475863e-05  5   0.497233   \n",
       "rainy_category           0.307631  0.019169  1.799651e-06  5   0.347100   \n",
       "power_increase_summer    0.301684  0.043049  4.843029e-05  5   0.390322   \n",
       "태양광용량                    0.300354  0.037768  2.938032e-05  5   0.378119   \n",
       "wind                     0.295872  0.047103  7.454769e-05  5   0.392858   \n",
       "cos_day                  0.285398  0.039949  4.488816e-05  5   0.367653   \n",
       "cos_time                 0.268347  0.035649  3.651239e-05  5   0.341749   \n",
       "sin_day                  0.211485  0.032100  6.178442e-05  5   0.277580   \n",
       "ESS저장용량                  0.175083  0.029336  9.114349e-05  5   0.235486   \n",
       "증가_day_hour_sum          0.155738  0.028557  1.297895e-04  5   0.214537   \n",
       "commute_period           0.115864  0.021297  1.310216e-04  5   0.159714   \n",
       "감소_day_hour_sum          0.092107  0.022289  3.812249e-04  5   0.138000   \n",
       "rainy                    0.082122  0.013327  8.037819e-05  5   0.109562   \n",
       "low_power_day            0.078621  0.009450  2.457282e-05  5   0.098079   \n",
       "heatwave_caution         0.076352  0.011474  5.938987e-05  5   0.099976   \n",
       "tem_x_hum_diff           0.059718  0.013064  2.581407e-04  5   0.086617   \n",
       "temp_diff                0.053959  0.013498  4.330944e-04  5   0.081751   \n",
       "month                    0.045390  0.007981  1.101161e-04  5   0.061823   \n",
       "body_temp                0.019421  0.003325  9.920998e-05  5   0.026267   \n",
       "PCS용량                    0.014723  0.002425  8.526906e-05  5   0.019717   \n",
       "heatwave_alert           0.012761  0.003801  8.420276e-04  5   0.020587   \n",
       "decrease_all             0.001783  0.000502  6.823533e-04  5   0.002817   \n",
       "holiday                  0.001070  0.000690  1.284079e-02  5   0.002491   \n",
       "increase_all             0.000864  0.000499  8.965876e-03  5   0.001890   \n",
       "THI_group                0.000613  0.000378  1.115871e-02  5   0.001391   \n",
       "\n",
       "                         p99_low  \n",
       "num_day_hour_mean      66.636504  \n",
       "date_time               5.954939  \n",
       "num_day_hour_std        5.032139  \n",
       "num                     1.334296  \n",
       "연면적                     1.404027  \n",
       "CDH                     1.214750  \n",
       "temp                    1.100455  \n",
       "power_diff_ratio        0.886751  \n",
       "태양광효율                   0.813807  \n",
       "냉방면적                    0.759111  \n",
       "tem_x_hum               0.707749  \n",
       "THI                     0.590757  \n",
       "연면_냉방면적                 0.486069  \n",
       "location                0.504999  \n",
       "week                    0.491978  \n",
       "hour                    0.313859  \n",
       "sin_time                0.292709  \n",
       "hum                     0.273504  \n",
       "day                     0.306128  \n",
       "tropical_night          0.289879  \n",
       "temp_wind               0.245639  \n",
       "rainy_category          0.268163  \n",
       "power_increase_summer   0.213046  \n",
       "태양광용량                   0.222589  \n",
       "wind                    0.198886  \n",
       "cos_day                 0.203143  \n",
       "cos_time                0.194945  \n",
       "sin_day                 0.145390  \n",
       "ESS저장용량                 0.114679  \n",
       "증가_day_hour_sum         0.096938  \n",
       "commute_period          0.072013  \n",
       "감소_day_hour_sum         0.046214  \n",
       "rainy                   0.054682  \n",
       "low_power_day           0.059163  \n",
       "heatwave_caution        0.052728  \n",
       "tem_x_hum_diff          0.032819  \n",
       "temp_diff               0.026167  \n",
       "month                   0.028957  \n",
       "body_temp               0.012574  \n",
       "PCS용량                   0.009729  \n",
       "heatwave_alert          0.004936  \n",
       "decrease_all            0.000749  \n",
       "holiday                -0.000351  \n",
       "increase_all           -0.000163  \n",
       "THI_group              -0.000166  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.feature_importance(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_date_time</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_20220825 00</td>\n",
       "      <td>2032.590085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_20220825 01</td>\n",
       "      <td>2001.954761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_20220825 02</td>\n",
       "      <td>1804.802206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_20220825 03</td>\n",
       "      <td>1708.447136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_20220825 04</td>\n",
       "      <td>1699.192685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16795</th>\n",
       "      <td>100_20220831 19</td>\n",
       "      <td>943.590352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16796</th>\n",
       "      <td>100_20220831 20</td>\n",
       "      <td>848.670576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16797</th>\n",
       "      <td>100_20220831 21</td>\n",
       "      <td>764.608321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16798</th>\n",
       "      <td>100_20220831 22</td>\n",
       "      <td>661.657046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16799</th>\n",
       "      <td>100_20220831 23</td>\n",
       "      <td>552.663516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16800 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         num_date_time       answer\n",
       "0        1_20220825 00  2032.590085\n",
       "1        1_20220825 01  2001.954761\n",
       "2        1_20220825 02  1804.802206\n",
       "3        1_20220825 03  1708.447136\n",
       "4        1_20220825 04  1699.192685\n",
       "...                ...          ...\n",
       "16795  100_20220831 19   943.590352\n",
       "16796  100_20220831 20   848.670576\n",
       "16797  100_20220831 21   764.608321\n",
       "16798  100_20220831 22   661.657046\n",
       "16799  100_20220831 23   552.663516\n",
       "\n",
       "[16800 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.read_csv('submission2.csv')\n",
    "b = pd.read_csv('submit_v12_xgb_optuna_iter41_8888.csv')\n",
    "c = a.copy()\n",
    "c['answer'] = 0\n",
    "c['answer'] = a['answer']*0.42185 + b['answer']*0.57815\n",
    "#c['answer'] = (a['answer'] + b['answer']) / 2\n",
    "c.to_csv('submit_v13_xgb_optuna_8512.csv',index=False)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_date_time</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_20220825 00</td>\n",
       "      <td>2201.706445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_20220825 01</td>\n",
       "      <td>2157.875354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_20220825 02</td>\n",
       "      <td>1942.385477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_20220825 03</td>\n",
       "      <td>1818.851477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_20220825 04</td>\n",
       "      <td>1827.483920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16795</th>\n",
       "      <td>100_20220831 19</td>\n",
       "      <td>923.047476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16796</th>\n",
       "      <td>100_20220831 20</td>\n",
       "      <td>850.975172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16797</th>\n",
       "      <td>100_20220831 21</td>\n",
       "      <td>780.236613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16798</th>\n",
       "      <td>100_20220831 22</td>\n",
       "      <td>650.756886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16799</th>\n",
       "      <td>100_20220831 23</td>\n",
       "      <td>558.424402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16800 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         num_date_time       answer\n",
       "0        1_20220825 00  2201.706445\n",
       "1        1_20220825 01  2157.875354\n",
       "2        1_20220825 02  1942.385477\n",
       "3        1_20220825 03  1818.851477\n",
       "4        1_20220825 04  1827.483920\n",
       "...                ...          ...\n",
       "16795  100_20220831 19   923.047476\n",
       "16796  100_20220831 20   850.975172\n",
       "16797  100_20220831 21   780.236613\n",
       "16798  100_20220831 22   650.756886\n",
       "16799  100_20220831 23   558.424402\n",
       "\n",
       "[16800 rows x 2 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.read_csv('11_12_xgb_41_720_8888_ens.csv')\n",
    "a['answer'] = a['answer'] * 1.05\n",
    "a.to_csv('sotapp.csv',index=False)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 각 빌딩별 Validation값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Iteration  Best Values\n",
      "0           1     3.309706\n",
      "1           2     6.319838\n",
      "2           3     6.023522\n",
      "3           4     3.278278\n",
      "4           5     4.923040\n",
      "..        ...          ...\n",
      "95         96     2.608702\n",
      "96         97     4.062261\n",
      "97         98     6.098842\n",
      "98         99     2.525203\n",
      "99        100     4.073055\n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# 파일을 열어서 문자열을 읽어옵니다.\n",
    "with open('best_params_values_0720v2.txt', 'r') as f:\n",
    "    string = f.read()\n",
    "\n",
    "# Extract the Iteration and Best Values\n",
    "pattern = r\"Iteration: (\\d+),.*?Best Values: ([\\d\\.]+)\"\n",
    "matches = re.findall(pattern, string, re.DOTALL)\n",
    "\n",
    "# Convert the matches into a DataFrame\n",
    "df = pd.DataFrame(matches, columns=[\"Iteration\", \"Best Values\"])\n",
    "df[\"Iteration\"] = df[\"Iteration\"].astype(int)\n",
    "df[\"Best Values\"] = df[\"Best Values\"].astype(float)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>건물번호</th>\n",
       "      <th>건물유형</th>\n",
       "      <th>Best Values</th>\n",
       "      <th>연면적(m2)</th>\n",
       "      <th>냉방면적(m2)</th>\n",
       "      <th>태양광용량(kW)</th>\n",
       "      <th>ESS저장용량(kWh)</th>\n",
       "      <th>PCS용량(kW)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>건물기타</td>\n",
       "      <td>3.309706</td>\n",
       "      <td>110634.00</td>\n",
       "      <td>39570.00</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>건물기타</td>\n",
       "      <td>6.319838</td>\n",
       "      <td>122233.47</td>\n",
       "      <td>99000.00</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>건물기타</td>\n",
       "      <td>6.023522</td>\n",
       "      <td>171243.00</td>\n",
       "      <td>113950.00</td>\n",
       "      <td>40</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>건물기타</td>\n",
       "      <td>3.278278</td>\n",
       "      <td>74312.98</td>\n",
       "      <td>34419.62</td>\n",
       "      <td>60</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>건물기타</td>\n",
       "      <td>4.923040</td>\n",
       "      <td>205884.00</td>\n",
       "      <td>150000.00</td>\n",
       "      <td>-</td>\n",
       "      <td>2557</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>호텔및리조트</td>\n",
       "      <td>2.608702</td>\n",
       "      <td>93314.00</td>\n",
       "      <td>60500.00</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>호텔및리조트</td>\n",
       "      <td>4.062261</td>\n",
       "      <td>55144.67</td>\n",
       "      <td>25880.00</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>호텔및리조트</td>\n",
       "      <td>6.098842</td>\n",
       "      <td>53578.62</td>\n",
       "      <td>17373.75</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>호텔및리조트</td>\n",
       "      <td>2.525203</td>\n",
       "      <td>53499.00</td>\n",
       "      <td>40636.00</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>호텔및리조트</td>\n",
       "      <td>4.073055</td>\n",
       "      <td>57497.84</td>\n",
       "      <td>40035.23</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    건물번호    건물유형  Best Values    연면적(m2)   냉방면적(m2) 태양광용량(kW) ESS저장용량(kWh)  \\\n",
       "0      1    건물기타     3.309706  110634.00   39570.00         -            -   \n",
       "1      2    건물기타     6.319838  122233.47   99000.00         -            -   \n",
       "2      3    건물기타     6.023522  171243.00  113950.00        40            -   \n",
       "3      4    건물기타     3.278278   74312.98   34419.62        60            -   \n",
       "4      5    건물기타     4.923040  205884.00  150000.00         -         2557   \n",
       "..   ...     ...          ...        ...        ...       ...          ...   \n",
       "95    96  호텔및리조트     2.608702   93314.00   60500.00         -            -   \n",
       "96    97  호텔및리조트     4.062261   55144.67   25880.00         -            -   \n",
       "97    98  호텔및리조트     6.098842   53578.62   17373.75         -            -   \n",
       "98    99  호텔및리조트     2.525203   53499.00   40636.00         -            -   \n",
       "99   100  호텔및리조트     4.073055   57497.84   40035.23         -            -   \n",
       "\n",
       "   PCS용량(kW)  \n",
       "0          -  \n",
       "1          -  \n",
       "2          -  \n",
       "3          -  \n",
       "4       1000  \n",
       "..       ...  \n",
       "95         -  \n",
       "96         -  \n",
       "97         -  \n",
       "98         -  \n",
       "99         -  \n",
       "\n",
       "[100 rows x 8 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info = pd.read_csv('building_info.csv')\n",
    "concat = pd.concat([info,df['Best Values']],axis=1)\n",
    "# Reorder the columns\n",
    "cols = concat.columns.tolist()  # Convert the column names into a list\n",
    "cols.insert(2, cols.pop(cols.index('Best Values')))  # Move 'Best Values' to the 3rd position (index 2)\n",
    "\n",
    "concat = concat[cols]  # Reindex the DataFrame\n",
    "concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Iteration  Best Values_day따로\n",
      "0            1           3.958431\n",
      "1            1           5.159142\n",
      "2            2           7.236492\n",
      "3            2           6.041059\n",
      "4            3           5.471286\n",
      "..         ...                ...\n",
      "154         96           2.694907\n",
      "155         97           3.705436\n",
      "156         98           6.647394\n",
      "157         99           2.348074\n",
      "158        100           4.307969\n",
      "\n",
      "[159 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# 파일을 열어서 문자열을 읽어옵니다.\n",
    "with open('best_params_values_0721.txt', 'r') as f:\n",
    "    string = f.read()\n",
    "\n",
    "# Extract the Iteration and Best Values\n",
    "pattern = r\"Iteration: (\\d+),.*?Best Values: ([\\d\\.]+)\"\n",
    "matches = re.findall(pattern, string, re.DOTALL)\n",
    "\n",
    "# Convert the matches into a DataFrame\n",
    "df = pd.DataFrame(matches, columns=[\"Iteration\", \"Best Values_day따로\"])\n",
    "df[\"Iteration\"] = df[\"Iteration\"].astype(int)\n",
    "df[\"Best Values_day따로\"] = df[\"Best Values_day따로\"].astype(float)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Best Values_day따로</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4.558786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6.638776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5.745692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3.593410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4.045336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>2.694907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>3.705436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>6.647394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>2.348074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>4.307969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Iteration  Best Values_day따로\n",
       "0           1           4.558786\n",
       "1           2           6.638776\n",
       "2           3           5.745692\n",
       "3           4           3.593410\n",
       "4           5           4.045336\n",
       "..        ...                ...\n",
       "95         96           2.694907\n",
       "96         97           3.705436\n",
       "97         98           6.647394\n",
       "98         99           2.348074\n",
       "99        100           4.307969\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the mean of 'Best Values' for each unique 'Iteration'\n",
    "df_mean = df.groupby('Iteration')['Best Values_day따로'].mean().reset_index()\n",
    "df_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>건물번호</th>\n",
       "      <th>건물유형</th>\n",
       "      <th>Best Values</th>\n",
       "      <th>Best Values_day따로</th>\n",
       "      <th>연면적(m2)</th>\n",
       "      <th>냉방면적(m2)</th>\n",
       "      <th>태양광용량(kW)</th>\n",
       "      <th>ESS저장용량(kWh)</th>\n",
       "      <th>PCS용량(kW)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>건물기타</td>\n",
       "      <td>3.309706</td>\n",
       "      <td>4.558786</td>\n",
       "      <td>110634.00</td>\n",
       "      <td>39570.00</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>건물기타</td>\n",
       "      <td>6.319838</td>\n",
       "      <td>6.638776</td>\n",
       "      <td>122233.47</td>\n",
       "      <td>99000.00</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>건물기타</td>\n",
       "      <td>6.023522</td>\n",
       "      <td>5.745692</td>\n",
       "      <td>171243.00</td>\n",
       "      <td>113950.00</td>\n",
       "      <td>40</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>건물기타</td>\n",
       "      <td>3.278278</td>\n",
       "      <td>3.593410</td>\n",
       "      <td>74312.98</td>\n",
       "      <td>34419.62</td>\n",
       "      <td>60</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>건물기타</td>\n",
       "      <td>4.923040</td>\n",
       "      <td>4.045336</td>\n",
       "      <td>205884.00</td>\n",
       "      <td>150000.00</td>\n",
       "      <td>-</td>\n",
       "      <td>2557</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>호텔및리조트</td>\n",
       "      <td>2.608702</td>\n",
       "      <td>2.694907</td>\n",
       "      <td>93314.00</td>\n",
       "      <td>60500.00</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>호텔및리조트</td>\n",
       "      <td>4.062261</td>\n",
       "      <td>3.705436</td>\n",
       "      <td>55144.67</td>\n",
       "      <td>25880.00</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>호텔및리조트</td>\n",
       "      <td>6.098842</td>\n",
       "      <td>6.647394</td>\n",
       "      <td>53578.62</td>\n",
       "      <td>17373.75</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>호텔및리조트</td>\n",
       "      <td>2.525203</td>\n",
       "      <td>2.348074</td>\n",
       "      <td>53499.00</td>\n",
       "      <td>40636.00</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>호텔및리조트</td>\n",
       "      <td>4.073055</td>\n",
       "      <td>4.307969</td>\n",
       "      <td>57497.84</td>\n",
       "      <td>40035.23</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    건물번호    건물유형  Best Values  Best Values_day따로    연면적(m2)   냉방면적(m2)  \\\n",
       "0      1    건물기타     3.309706           4.558786  110634.00   39570.00   \n",
       "1      2    건물기타     6.319838           6.638776  122233.47   99000.00   \n",
       "2      3    건물기타     6.023522           5.745692  171243.00  113950.00   \n",
       "3      4    건물기타     3.278278           3.593410   74312.98   34419.62   \n",
       "4      5    건물기타     4.923040           4.045336  205884.00  150000.00   \n",
       "..   ...     ...          ...                ...        ...        ...   \n",
       "95    96  호텔및리조트     2.608702           2.694907   93314.00   60500.00   \n",
       "96    97  호텔및리조트     4.062261           3.705436   55144.67   25880.00   \n",
       "97    98  호텔및리조트     6.098842           6.647394   53578.62   17373.75   \n",
       "98    99  호텔및리조트     2.525203           2.348074   53499.00   40636.00   \n",
       "99   100  호텔및리조트     4.073055           4.307969   57497.84   40035.23   \n",
       "\n",
       "   태양광용량(kW) ESS저장용량(kWh) PCS용량(kW)  \n",
       "0          -            -         -  \n",
       "1          -            -         -  \n",
       "2         40            -         -  \n",
       "3         60            -         -  \n",
       "4          -         2557      1000  \n",
       "..       ...          ...       ...  \n",
       "95         -            -         -  \n",
       "96         -            -         -  \n",
       "97         -            -         -  \n",
       "98         -            -         -  \n",
       "99         -            -         -  \n",
       "\n",
       "[100 rows x 9 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat = pd.concat([concat,df_mean['Best Values_day따로']],axis=1)\n",
    "# Reorder the columns\n",
    "cols = concat.columns.tolist()  # Convert the column names into a list\n",
    "cols.insert(3, cols.pop(cols.index('Best Values_day따로')))  # Move 'Best Values' to the 3rd position (index 2)\n",
    "\n",
    "concat = concat[cols]  # Reindex the DataFrame\n",
    "concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat.to_csv('빌딩별_validation.csv',index=False, encoding = \"CP949\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
